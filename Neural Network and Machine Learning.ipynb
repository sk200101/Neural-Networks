{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e43b8e",
   "metadata": {},
   "source": [
    "# Single Layer Perceptron For NOT, AND, OR , NAND, NOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c2f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT(0) = 1\n",
      "NOT(1) = 0\n",
      "\n",
      "\n",
      "\n",
      "AND(0,0) = 0\n",
      "AND(0,1) = 0\n",
      "AND(1,0) = 0\n",
      "AND(1,1) = 1\n",
      "\n",
      "\n",
      "\n",
      "NAND(0,0) = 1\n",
      "NAND(0,1) = 1\n",
      "NAND(1,0) = 1\n",
      "NAND(1,1) = 0\n",
      "\n",
      "\n",
      "\n",
      "OR(0,0) = 0\n",
      "OR(0,1) = 1\n",
      "OR(1,0) = 1\n",
      "OR(1,1) = 1\n",
      "\n",
      "\n",
      "\n",
      "NOR(0,0) = 1\n",
      "NOR(0,1) = 0\n",
      "NOR(1,0) = 0\n",
      "NOR(1,1) = 0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unit_step(v):\n",
    "    if v >= 0:\n",
    "        return 1;\n",
    "    else:\n",
    "        return 0;\n",
    "    \n",
    "def perceptron(x,w,b):\n",
    "    v = np.dot(x,w) + b\n",
    "    y = unit_step(v)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def NOT(x):\n",
    "    w = -1\n",
    "    b = 0.5\n",
    "    return perceptron(x,w,b)\n",
    "\n",
    "print(\"NOT({}) = {}\".format(0,NOT(0)));\n",
    "print(\"NOT({}) = {}\".format(1,NOT(1)));\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "def AND(x):\n",
    "    w = np.array([1,1])\n",
    "    b = -1.5\n",
    "    return perceptron(x,w,b)\n",
    "\n",
    "print(\"AND({},{}) = {}\".format(0,0,AND([0,0])))\n",
    "print(\"AND({},{}) = {}\".format(0,1,AND([0,1])))\n",
    "print(\"AND({},{}) = {}\".format(1,0,AND([1,0])))\n",
    "print(\"AND({},{}) = {}\".format(1,1,AND([1,1])))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "def NAND(x):\n",
    "    a = AND(x)\n",
    "    n = NOT(a)\n",
    "    return n\n",
    "\n",
    "print(\"NAND({},{}) = {}\".format(0,0,NAND([0,0])))\n",
    "print(\"NAND({},{}) = {}\".format(0,1,NAND([0,1])))\n",
    "print(\"NAND({},{}) = {}\".format(1,0,NAND([1,0])))\n",
    "print(\"NAND({},{}) = {}\".format(1,1,NAND([1,1])))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "def OR(x):\n",
    "    w = np.array([1,1])\n",
    "    b = -0.5\n",
    "    return perceptron(x,w,b)\n",
    "\n",
    "print(\"OR({},{}) = {}\".format(0,0,OR([0,0])))\n",
    "print(\"OR({},{}) = {}\".format(0,1,OR([0,1])))\n",
    "print(\"OR({},{}) = {}\".format(1,0,OR([1,0])))\n",
    "print(\"OR({},{}) = {}\".format(1,1,OR([1,1])))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "def NOR(x):\n",
    "    o = OR(x)\n",
    "    n = NOT(o)\n",
    "    return n\n",
    "\n",
    "\n",
    "print(\"NOR({},{}) = {}\".format(0,0,NOR([0,0])))\n",
    "print(\"NOR({},{}) = {}\".format(0,1,NOR([0,1])))\n",
    "print(\"NOR({},{}) = {}\".format(1,0,NOR([1,0])))\n",
    "print(\"NOR({},{}) = {}\".format(1,1,NOR([1,1])))\n",
    "print(\"\\n\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d9b85",
   "metadata": {},
   "source": [
    "# Single Layer Perceptron For Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3fdeb45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error - Updating weight to: [-0.0007199999999999999, -0.00082]\n",
      "\n",
      "Error - Updating weight to: [-0.00164, -0.00041999999999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.0024200000000000003, -0.0012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.0024200000000000003, -0.0012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.0024200000000000003, -0.0012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.0024200000000000003, -0.0012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.0031400000000000004, -0.0021]\n",
      "\n",
      "Error - Updating weight to: [-0.00406, -0.0017]\n",
      "\n",
      "Error - Updating weight to: [-0.0048400000000000006, -0.0025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.0048400000000000006, -0.0025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.0048400000000000006, -0.0025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.0048400000000000006, -0.0025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.005560000000000001, -0.0033799999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.0064800000000000005, -0.0029799999999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.007260000000000001, -0.0038399999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.007260000000000001, -0.0038399999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.007260000000000001, -0.0038399999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.007260000000000001, -0.0038399999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.007980000000000001, -0.004659999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.008900000000000002, -0.004259999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.009680000000000001, -0.005119999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.009680000000000001, -0.005119999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.009680000000000001, -0.005119999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.009680000000000001, -0.005119999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.010400000000000001, -0.005939999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.011320000000000002, -0.005539999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.012100000000000001, -0.006399999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.012100000000000001, -0.006399999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.012100000000000001, -0.006399999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.012100000000000001, -0.006399999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.012820000000000002, -0.007219999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.013740000000000002, -0.006819999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.014520000000000002, -0.0076799999999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.014520000000000002, -0.0076799999999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.014520000000000002, -0.0076799999999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.014520000000000002, -0.0076799999999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.015240000000000002, -0.008499999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.01616, -0.0081]\n",
      "\n",
      "Error - Updating weight to: [-0.01694, -0.00896]\n",
      "\n",
      "Error - Updating weight to: [-0.01694, -0.00896]\n",
      "\n",
      "Error - Updating weight to: [-0.01694, -0.00896]\n",
      "\n",
      "Error - Updating weight to: [-0.01694, -0.00896]\n",
      "\n",
      "Error - Updating weight to: [-0.01766, -0.009779999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.01858, -0.00938]\n",
      "\n",
      "Error - Updating weight to: [-0.01936, -0.010239999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.01936, -0.010239999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.01936, -0.010239999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.01936, -0.010239999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.020079999999999997, -0.011059999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.020999999999999998, -0.01066]\n",
      "\n",
      "Error - Updating weight to: [-0.021779999999999997, -0.011519999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.021779999999999997, -0.011519999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.021779999999999997, -0.011519999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.021779999999999997, -0.011519999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.022499999999999996, -0.012339999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.023419999999999996, -0.01194]\n",
      "\n",
      "Error - Updating weight to: [-0.024199999999999996, -0.012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.024199999999999996, -0.012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.024199999999999996, -0.012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.024199999999999996, -0.012799999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.024919999999999994, -0.013619999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.025839999999999995, -0.013219999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.026619999999999994, -0.014079999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.026619999999999994, -0.014079999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.026619999999999994, -0.014079999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.026619999999999994, -0.014079999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.027339999999999993, -0.014899999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.028259999999999993, -0.014499999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.029039999999999993, -0.015359999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.029039999999999993, -0.015359999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.029039999999999993, -0.015359999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.029039999999999993, -0.015359999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.02975999999999999, -0.01618]\n",
      "\n",
      "Error - Updating weight to: [-0.030679999999999992, -0.01578]\n",
      "\n",
      "Error - Updating weight to: [-0.031459999999999995, -0.01664]\n",
      "\n",
      "Error - Updating weight to: [-0.031459999999999995, -0.01664]\n",
      "\n",
      "Error - Updating weight to: [-0.031459999999999995, -0.01664]\n",
      "\n",
      "Error - Updating weight to: [-0.031459999999999995, -0.01664]\n",
      "\n",
      "Error - Updating weight to: [-0.03217999999999999, -0.01746]\n",
      "\n",
      "Error - Updating weight to: [-0.03309999999999999, -0.01706]\n",
      "\n",
      "Error - Updating weight to: [-0.03387999999999999, -0.01792]\n",
      "\n",
      "Error - Updating weight to: [-0.03387999999999999, -0.01792]\n",
      "\n",
      "Error - Updating weight to: [-0.03387999999999999, -0.01792]\n",
      "\n",
      "Error - Updating weight to: [-0.03387999999999999, -0.01792]\n",
      "\n",
      "Error - Updating weight to: [-0.03459999999999999, -0.01874]\n",
      "\n",
      "Error - Updating weight to: [-0.03551999999999999, -0.01834]\n",
      "\n",
      "Error - Updating weight to: [-0.03629999999999999, -0.0192]\n",
      "\n",
      "Error - Updating weight to: [-0.03629999999999999, -0.0192]\n",
      "\n",
      "Error - Updating weight to: [-0.03629999999999999, -0.0192]\n",
      "\n",
      "Error - Updating weight to: [-0.03629999999999999, -0.0192]\n",
      "\n",
      "Error - Updating weight to: [-0.03701999999999999, -0.02002]\n",
      "\n",
      "Error - Updating weight to: [-0.03793999999999999, -0.01962]\n",
      "\n",
      "Error - Updating weight to: [-0.03871999999999999, -0.020479999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.03871999999999999, -0.020479999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.03871999999999999, -0.020479999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.03871999999999999, -0.020479999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.03943999999999999, -0.0213]\n",
      "\n",
      "Error - Updating weight to: [-0.040359999999999986, -0.0209]\n",
      "\n",
      "Error - Updating weight to: [-0.04113999999999999, -0.021759999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04113999999999999, -0.021759999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04113999999999999, -0.021759999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04113999999999999, -0.021759999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04185999999999999, -0.02258]\n",
      "\n",
      "Error - Updating weight to: [-0.042779999999999985, -0.02218]\n",
      "\n",
      "Error - Updating weight to: [-0.04355999999999999, -0.023039999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04355999999999999, -0.023039999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04355999999999999, -0.023039999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04355999999999999, -0.023039999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.044279999999999986, -0.02386]\n",
      "\n",
      "Error - Updating weight to: [-0.04519999999999998, -0.023459999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.045979999999999986, -0.024319999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.045979999999999986, -0.024319999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.045979999999999986, -0.024319999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.045979999999999986, -0.024319999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.046699999999999985, -0.02514]\n",
      "\n",
      "Error - Updating weight to: [-0.04761999999999998, -0.024739999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.048399999999999985, -0.025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.048399999999999985, -0.025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.048399999999999985, -0.025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.048399999999999985, -0.025599999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.04911999999999998, -0.02642]\n",
      "\n",
      "Error - Updating weight to: [-0.05003999999999998, -0.026019999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05081999999999998, -0.026879999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05081999999999998, -0.026879999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05081999999999998, -0.026879999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05081999999999998, -0.026879999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05153999999999998, -0.0277]\n",
      "\n",
      "Error - Updating weight to: [-0.05245999999999998, -0.027299999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05323999999999998, -0.028159999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05323999999999998, -0.028159999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05323999999999998, -0.028159999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05323999999999998, -0.028159999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05395999999999998, -0.02898]\n",
      "\n",
      "Error - Updating weight to: [-0.05487999999999998, -0.028579999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05565999999999998, -0.029439999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05565999999999998, -0.029439999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05565999999999998, -0.029439999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05565999999999998, -0.029439999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05637999999999998, -0.03026]\n",
      "\n",
      "Error - Updating weight to: [-0.057299999999999976, -0.029859999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.05807999999999998, -0.030719999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05807999999999998, -0.030719999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05807999999999998, -0.030719999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05807999999999998, -0.030719999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.05879999999999998, -0.03154]\n",
      "\n",
      "Error - Updating weight to: [-0.059719999999999974, -0.031139999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.06049999999999998, -0.032]\n",
      "\n",
      "Error - Updating weight to: [-0.06049999999999998, -0.032]\n",
      "\n",
      "Error - Updating weight to: [-0.06049999999999998, -0.032]\n",
      "\n",
      "Error - Updating weight to: [-0.06049999999999998, -0.032]\n",
      "\n",
      "Error - Updating weight to: [-0.061219999999999976, -0.03282]\n",
      "\n",
      "Error - Updating weight to: [-0.06213999999999997, -0.032420000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.06291999999999998, -0.033280000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.06291999999999998, -0.033280000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.06291999999999998, -0.033280000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.06291999999999998, -0.033280000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.06363999999999997, -0.034100000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.06455999999999998, -0.03370000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06533999999999998, -0.03456000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06533999999999998, -0.03456000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06533999999999998, -0.03456000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06533999999999998, -0.03456000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06605999999999998, -0.03538000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06697999999999998, -0.03498000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06775999999999999, -0.03584000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06775999999999999, -0.03584000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06775999999999999, -0.03584000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06775999999999999, -0.03584000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06847999999999999, -0.03666000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.06939999999999999, -0.036260000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.07017999999999999, -0.037120000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.07017999999999999, -0.037120000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.07017999999999999, -0.037120000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.07017999999999999, -0.037120000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.07089999999999999, -0.037940000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.07182, -0.03754000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.0726, -0.03840000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.0726, -0.03840000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.0726, -0.03840000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.0726, -0.03840000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07332, -0.03922000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07424, -0.03882000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07502, -0.03968000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07502, -0.03968000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07502, -0.03968000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07502, -0.03968000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07574, -0.04050000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.07666, -0.040100000000000025]\n",
      "\n",
      "Error - Updating weight to: [-0.07744000000000001, -0.040960000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.07744000000000001, -0.040960000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.07744000000000001, -0.040960000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.07744000000000001, -0.040960000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.07816000000000001, -0.041780000000000025]\n",
      "\n",
      "Error - Updating weight to: [-0.07908000000000001, -0.04138000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.07986000000000001, -0.04224000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.07986000000000001, -0.04224000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.07986000000000001, -0.04224000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.07986000000000001, -0.04224000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08058000000000001, -0.04306000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08150000000000002, -0.04266000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08228000000000002, -0.04352000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08228000000000002, -0.04352000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08228000000000002, -0.04352000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08228000000000002, -0.04352000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08300000000000002, -0.04434000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.08392000000000002, -0.043940000000000035]\n",
      "\n",
      "Error - Updating weight to: [-0.08470000000000003, -0.044800000000000034]\n",
      "\n",
      "Error - Updating weight to: [-0.08470000000000003, -0.044800000000000034]\n",
      "\n",
      "Error - Updating weight to: [-0.08470000000000003, -0.044800000000000034]\n",
      "\n",
      "Error - Updating weight to: [-0.08470000000000003, -0.044800000000000034]\n",
      "\n",
      "Error - Updating weight to: [-0.08542000000000002, -0.045620000000000036]\n",
      "\n",
      "Error - Updating weight to: [-0.08634000000000003, -0.04522000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08712000000000003, -0.04608000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08712000000000003, -0.04608000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08712000000000003, -0.04608000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08712000000000003, -0.04608000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08784000000000003, -0.04690000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08876000000000003, -0.04650000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08954000000000004, -0.04736000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08954000000000004, -0.04736000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08954000000000004, -0.04736000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.08954000000000004, -0.04736000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.09026000000000003, -0.04818000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.09118000000000004, -0.047780000000000045]\n",
      "\n",
      "Error - Updating weight to: [-0.09196000000000004, -0.048640000000000044]\n",
      "\n",
      "Error - Updating weight to: [-0.09196000000000004, -0.048640000000000044]\n",
      "\n",
      "Error - Updating weight to: [-0.09196000000000004, -0.048640000000000044]\n",
      "\n",
      "Error - Updating weight to: [-0.09196000000000004, -0.048640000000000044]\n",
      "\n",
      "Error - Updating weight to: [-0.09268000000000004, -0.049460000000000046]\n",
      "\n",
      "Error - Updating weight to: [-0.09360000000000004, -0.04906000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09438000000000005, -0.04992000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09438000000000005, -0.04992000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09438000000000005, -0.04992000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09438000000000005, -0.04992000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09510000000000005, -0.05074000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09602000000000005, -0.05034000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09680000000000005, -0.05120000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09680000000000005, -0.05120000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09680000000000005, -0.05120000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09680000000000005, -0.05120000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09752000000000005, -0.05202000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.09844000000000006, -0.051620000000000055]\n",
      "\n",
      "Error - Updating weight to: [-0.09922000000000006, -0.052480000000000054]\n",
      "\n",
      "Error - Updating weight to: [-0.09922000000000006, -0.052480000000000054]\n",
      "\n",
      "Error - Updating weight to: [-0.09922000000000006, -0.052480000000000054]\n",
      "\n",
      "Error - Updating weight to: [-0.09922000000000006, -0.052480000000000054]\n",
      "\n",
      "Error - Updating weight to: [-0.09994000000000006, -0.053300000000000056]\n",
      "\n",
      "Error - Updating weight to: [-0.10086000000000006, -0.05290000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10164000000000006, -0.05376000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10164000000000006, -0.05376000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10164000000000006, -0.05376000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10164000000000006, -0.05376000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10236000000000006, -0.05458000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10328000000000007, -0.05418000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10406000000000007, -0.05504000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10406000000000007, -0.05504000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10406000000000007, -0.05504000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10406000000000007, -0.05504000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10478000000000007, -0.05586000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.10570000000000007, -0.055460000000000065]\n",
      "\n",
      "Error - Updating weight to: [-0.10648000000000007, -0.056320000000000064]\n",
      "\n",
      "Error - Updating weight to: [-0.10648000000000007, -0.056320000000000064]\n",
      "\n",
      "Error - Updating weight to: [-0.10648000000000007, -0.056320000000000064]\n",
      "\n",
      "Error - Updating weight to: [-0.10648000000000007, -0.056320000000000064]\n",
      "\n",
      "Error - Updating weight to: [-0.10720000000000007, -0.057140000000000066]\n",
      "\n",
      "Error - Updating weight to: [-0.10812000000000008, -0.05674000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.10890000000000008, -0.05760000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.10890000000000008, -0.05760000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.10890000000000008, -0.05760000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.10890000000000008, -0.05760000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.10962000000000008, -0.05842000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.11054000000000008, -0.05802000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.11132000000000009, -0.05888000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.11132000000000009, -0.05888000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.11132000000000009, -0.05888000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.11132000000000009, -0.05888000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.11204000000000008, -0.05970000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.11296000000000009, -0.059300000000000075]\n",
      "\n",
      "Error - Updating weight to: [-0.11374000000000009, -0.060160000000000075]\n",
      "\n",
      "Error - Updating weight to: [-0.11374000000000009, -0.060160000000000075]\n",
      "\n",
      "Error - Updating weight to: [-0.11374000000000009, -0.060160000000000075]\n",
      "\n",
      "Error - Updating weight to: [-0.11374000000000009, -0.060160000000000075]\n",
      "\n",
      "Error - Updating weight to: [-0.11446000000000009, -0.060980000000000076]\n",
      "\n",
      "Error - Updating weight to: [-0.1153800000000001, -0.06058000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1161600000000001, -0.06144000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1161600000000001, -0.06144000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1161600000000001, -0.06144000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1161600000000001, -0.06144000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1168800000000001, -0.06226000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1178000000000001, -0.06186000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1185800000000001, -0.06272000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1185800000000001, -0.06272000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1185800000000001, -0.06272000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1185800000000001, -0.06272000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1193000000000001, -0.06354000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1202200000000001, -0.06314000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.12100000000000011, -0.06400000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.12100000000000011, -0.06400000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.12100000000000011, -0.06400000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.12100000000000011, -0.06400000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.1217200000000001, -0.06482000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12264000000000011, -0.06442000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12342000000000011, -0.06528000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12342000000000011, -0.06528000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12342000000000011, -0.06528000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12342000000000011, -0.06528000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12414000000000011, -0.06610000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12506000000000012, -0.06570000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12584000000000012, -0.06656000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12584000000000012, -0.06656000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12584000000000012, -0.06656000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12584000000000012, -0.06656000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12656000000000012, -0.06738000000000009]\n",
      "\n",
      "Error - Updating weight to: [-0.12748000000000012, -0.0669800000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.12826000000000012, -0.0678400000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.12826000000000012, -0.0678400000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.12826000000000012, -0.0678400000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.12826000000000012, -0.0678400000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.12898000000000012, -0.0686600000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.12990000000000013, -0.0682600000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13068000000000013, -0.0691200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13068000000000013, -0.0691200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13068000000000013, -0.0691200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13068000000000013, -0.0691200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13140000000000013, -0.0699400000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13232000000000013, -0.0695400000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13310000000000013, -0.0704000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13310000000000013, -0.0704000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13310000000000013, -0.0704000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13310000000000013, -0.0704000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13382000000000013, -0.0712200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13474000000000014, -0.0708200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13552000000000014, -0.0716800000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13552000000000014, -0.0716800000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13552000000000014, -0.0716800000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13552000000000014, -0.0716800000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13624000000000014, -0.0725000000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.13716000000000014, -0.07210000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.13794000000000015, -0.07296000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.13794000000000015, -0.07296000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.13794000000000015, -0.07296000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.13794000000000015, -0.07296000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.13866000000000014, -0.07378000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.13958000000000015, -0.07338000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14036000000000015, -0.07424000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14036000000000015, -0.07424000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14036000000000015, -0.07424000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14036000000000015, -0.07424000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14108000000000015, -0.07506000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14200000000000015, -0.07466000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14278000000000016, -0.07552000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14278000000000016, -0.07552000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14278000000000016, -0.07552000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14278000000000016, -0.07552000000000011]\n",
      "\n",
      "Error - Updating weight to: [-0.14350000000000016, -0.07634000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14442000000000016, -0.07594000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14520000000000016, -0.07680000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14520000000000016, -0.07680000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14520000000000016, -0.07680000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14520000000000016, -0.07680000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14592000000000016, -0.07762000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14684000000000016, -0.07722000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14762000000000017, -0.07808000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14762000000000017, -0.07808000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14762000000000017, -0.07808000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14762000000000017, -0.07808000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14834000000000017, -0.07890000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.14926000000000017, -0.07850000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15004000000000017, -0.07936000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.15004000000000017, -0.07936000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.15004000000000017, -0.07936000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.15004000000000017, -0.07936000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.15076000000000017, -0.08018000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15168000000000018, -0.07978000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15246000000000018, -0.08064000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15246000000000018, -0.08064000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15246000000000018, -0.08064000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15246000000000018, -0.08064000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15318000000000018, -0.08146000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15410000000000018, -0.08106000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15488000000000018, -0.08192000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15488000000000018, -0.08192000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15488000000000018, -0.08192000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15488000000000018, -0.08192000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.15560000000000018, -0.08274000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.1565200000000002, -0.08234000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1573000000000002, -0.08320000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.1573000000000002, -0.08320000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.1573000000000002, -0.08320000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.1573000000000002, -0.08320000000000013]\n",
      "\n",
      "Error - Updating weight to: [-0.1580200000000002, -0.08402000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1589400000000002, -0.08362000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1597200000000002, -0.08448000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1597200000000002, -0.08448000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1597200000000002, -0.08448000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1597200000000002, -0.08448000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1604400000000002, -0.08530000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1613600000000002, -0.08490000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1621400000000002, -0.08576000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1621400000000002, -0.08576000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1621400000000002, -0.08576000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1621400000000002, -0.08576000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1628600000000002, -0.08658000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.1637800000000002, -0.08618000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1645600000000002, -0.08704000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1645600000000002, -0.08704000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1645600000000002, -0.08704000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1645600000000002, -0.08704000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1652800000000002, -0.08786000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1662000000000002, -0.08746000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1669800000000002, -0.08832000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1669800000000002, -0.08832000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1669800000000002, -0.08832000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1669800000000002, -0.08832000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.1677000000000002, -0.08914000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.16862000000000021, -0.08874000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.16940000000000022, -0.08960000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.16940000000000022, -0.08960000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.16940000000000022, -0.08960000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.16940000000000022, -0.08960000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.17012000000000022, -0.09042000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.17104000000000022, -0.09002000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17182000000000022, -0.09088000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17182000000000022, -0.09088000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17182000000000022, -0.09088000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17182000000000022, -0.09088000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17254000000000022, -0.09170000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17346000000000023, -0.09130000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17424000000000023, -0.09216000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17424000000000023, -0.09216000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17424000000000023, -0.09216000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17424000000000023, -0.09216000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17496000000000023, -0.09298000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17588000000000023, -0.09258000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17666000000000023, -0.09344000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17666000000000023, -0.09344000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17666000000000023, -0.09344000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17666000000000023, -0.09344000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17738000000000023, -0.09426000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.17830000000000024, -0.09386000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.17908000000000024, -0.09472000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.17908000000000024, -0.09472000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.17908000000000024, -0.09472000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.17908000000000024, -0.09472000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.17980000000000024, -0.09554000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18072000000000024, -0.09514000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18150000000000024, -0.09600000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18150000000000024, -0.09600000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18150000000000024, -0.09600000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18150000000000024, -0.09600000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18222000000000024, -0.09682000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18314000000000025, -0.09642000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18392000000000025, -0.09728000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18392000000000025, -0.09728000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18392000000000025, -0.09728000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18392000000000025, -0.09728000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18464000000000025, -0.09810000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.18556000000000025, -0.09770000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18634000000000026, -0.09856000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18634000000000026, -0.09856000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18634000000000026, -0.09856000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18634000000000026, -0.09856000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18706000000000025, -0.09938000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18798000000000026, -0.09898000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18876000000000026, -0.09984000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18876000000000026, -0.09984000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18876000000000026, -0.09984000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18876000000000026, -0.09984000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.18948000000000026, -0.10066000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.19040000000000026, -0.10026000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.19118000000000027, -0.10112000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.19118000000000027, -0.10112000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.19118000000000027, -0.10112000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.19118000000000027, -0.10112000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.19190000000000026, -0.10194000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.19282000000000027, -0.10154000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19360000000000027, -0.10240000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19360000000000027, -0.10240000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19360000000000027, -0.10240000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19360000000000027, -0.10240000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19432000000000027, -0.10322000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19524000000000027, -0.10282000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19602000000000028, -0.10368000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19602000000000028, -0.10368000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19602000000000028, -0.10368000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19602000000000028, -0.10368000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19674000000000028, -0.10450000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19766000000000028, -0.10410000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19844000000000028, -0.10496000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19844000000000028, -0.10496000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19844000000000028, -0.10496000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19844000000000028, -0.10496000000000019]\n",
      "\n",
      "Error - Updating weight to: [-0.19916000000000028, -0.1057800000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.20008000000000029, -0.1053800000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2008600000000003, -0.1062400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2008600000000003, -0.1062400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2008600000000003, -0.1062400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2008600000000003, -0.1062400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2015800000000003, -0.1070600000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2025000000000003, -0.1066600000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2032800000000003, -0.1075200000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2032800000000003, -0.1075200000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2032800000000003, -0.1075200000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2032800000000003, -0.1075200000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2040000000000003, -0.1083400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2049200000000003, -0.1079400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2057000000000003, -0.1088000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2057000000000003, -0.1088000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2057000000000003, -0.1088000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2057000000000003, -0.1088000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2064200000000003, -0.1096200000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2073400000000003, -0.1092200000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2081200000000003, -0.1100800000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2081200000000003, -0.1100800000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2081200000000003, -0.1100800000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2081200000000003, -0.1100800000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2088400000000003, -0.1109000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.2097600000000003, -0.11050000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.2105400000000003, -0.11136000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.2105400000000003, -0.11136000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.2105400000000003, -0.11136000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.2105400000000003, -0.11136000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.2112600000000003, -0.11218000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.2121800000000003, -0.11178000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.21296000000000032, -0.11264000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.21296000000000032, -0.11264000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.21296000000000032, -0.11264000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.21296000000000032, -0.11264000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.21368000000000031, -0.11346000000000021]\n",
      "\n",
      "Error - Updating weight to: [-0.21460000000000032, -0.11306000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21538000000000032, -0.11392000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21538000000000032, -0.11392000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21538000000000032, -0.11392000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21538000000000032, -0.11392000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21610000000000032, -0.11474000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21702000000000032, -0.11434000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21780000000000033, -0.11520000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21780000000000033, -0.11520000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21780000000000033, -0.11520000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21780000000000033, -0.11520000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21852000000000033, -0.11602000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.21944000000000033, -0.11562000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.22022000000000033, -0.11648000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.22022000000000033, -0.11648000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.22022000000000033, -0.11648000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.22022000000000033, -0.11648000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.22094000000000033, -0.11730000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.22186000000000033, -0.11690000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22264000000000034, -0.11776000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22264000000000034, -0.11776000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22264000000000034, -0.11776000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22264000000000034, -0.11776000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22336000000000034, -0.11858000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22428000000000034, -0.11818000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22506000000000034, -0.11904000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22506000000000034, -0.11904000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22506000000000034, -0.11904000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22506000000000034, -0.11904000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22578000000000034, -0.11986000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22670000000000035, -0.11946000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22748000000000035, -0.12032000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22748000000000035, -0.12032000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22748000000000035, -0.12032000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22748000000000035, -0.12032000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22820000000000035, -0.12114000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.22912000000000035, -0.12074000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.22990000000000035, -0.12160000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.22990000000000035, -0.12160000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.22990000000000035, -0.12160000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.22990000000000035, -0.12160000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23062000000000035, -0.12242000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23154000000000036, -0.12202000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23232000000000036, -0.12288000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23232000000000036, -0.12288000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23232000000000036, -0.12288000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23232000000000036, -0.12288000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23304000000000036, -0.12370000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23396000000000036, -0.12330000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23474000000000037, -0.12416000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23474000000000037, -0.12416000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23474000000000037, -0.12416000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23474000000000037, -0.12416000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23546000000000036, -0.12498000000000024]\n",
      "\n",
      "Error - Updating weight to: [-0.23638000000000037, -0.12458000000000025]\n",
      "\n",
      "Error - Updating weight to: [-0.23716000000000037, -0.12544000000000025]\n",
      "\n",
      "Error - Updating weight to: [-0.23716000000000037, -0.12544000000000025]\n",
      "\n",
      "Error - Updating weight to: [-0.23716000000000037, -0.12544000000000025]\n",
      "\n",
      "Error - Updating weight to: [-0.23716000000000037, -0.12544000000000025]\n",
      "\n",
      "Error - Updating weight to: [-0.23788000000000037, -0.12626000000000023]\n",
      "\n",
      "Error - Updating weight to: [-0.23880000000000037, -0.12586000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.23958000000000038, -0.12672000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.23958000000000038, -0.12672000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.23958000000000038, -0.12672000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.23958000000000038, -0.12672000000000022]\n",
      "\n",
      "Error - Updating weight to: [-0.24030000000000037, -0.1275400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.24122000000000038, -0.1271400000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.24200000000000038, -0.1280000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.24200000000000038, -0.1280000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.24200000000000038, -0.1280000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.24200000000000038, -0.1280000000000002]\n",
      "\n",
      "Error - Updating weight to: [-0.24272000000000038, -0.12882000000000018]\n",
      "\n",
      "Error - Updating weight to: [-0.24364000000000038, -0.12842000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.2444200000000004, -0.12928000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.2444200000000004, -0.12928000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.2444200000000004, -0.12928000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.2444200000000004, -0.12928000000000017]\n",
      "\n",
      "Error - Updating weight to: [-0.24514000000000039, -0.13010000000000016]\n",
      "\n",
      "Error - Updating weight to: [-0.2460600000000004, -0.12970000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.2468400000000004, -0.13056000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.2468400000000004, -0.13056000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.2468400000000004, -0.13056000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.2468400000000004, -0.13056000000000015]\n",
      "\n",
      "Error - Updating weight to: [-0.2475600000000004, -0.13138000000000014]\n",
      "\n",
      "Error - Updating weight to: [-0.2484800000000004, -0.13098000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.2492600000000004, -0.13184000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.2492600000000004, -0.13184000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.2492600000000004, -0.13184000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.2492600000000004, -0.13184000000000012]\n",
      "\n",
      "Error - Updating weight to: [-0.2499800000000004, -0.1326600000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.2509000000000004, -0.1322600000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.2516800000000004, -0.1331200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.2516800000000004, -0.1331200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.2516800000000004, -0.1331200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.2516800000000004, -0.1331200000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.2524000000000004, -0.1339400000000001]\n",
      "\n",
      "Error - Updating weight to: [-0.2533200000000004, -0.13354000000000008]\n",
      "\n",
      "Error - Updating weight to: [-0.2541000000000004, -0.13440000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.2541000000000004, -0.13440000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.2541000000000004, -0.13440000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.2541000000000004, -0.13440000000000007]\n",
      "\n",
      "Error - Updating weight to: [-0.2548200000000004, -0.13522000000000006]\n",
      "\n",
      "Error - Updating weight to: [-0.25574000000000036, -0.13482000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.25652000000000036, -0.13568000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.25652000000000036, -0.13568000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.25652000000000036, -0.13568000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.25652000000000036, -0.13568000000000005]\n",
      "\n",
      "Error - Updating weight to: [-0.25724000000000036, -0.13650000000000004]\n",
      "\n",
      "Error - Updating weight to: [-0.25816000000000033, -0.13610000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.25894000000000034, -0.13696000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.25894000000000034, -0.13696000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.25894000000000034, -0.13696000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.25894000000000034, -0.13696000000000003]\n",
      "\n",
      "Error - Updating weight to: [-0.25966000000000033, -0.13778]\n",
      "\n",
      "Error - Updating weight to: [-0.2605800000000003, -0.13738]\n",
      "\n",
      "Error - Updating weight to: [-0.2613600000000003, -0.13824]\n",
      "\n",
      "Error - Updating weight to: [-0.2613600000000003, -0.13824]\n",
      "\n",
      "Error - Updating weight to: [-0.2613600000000003, -0.13824]\n",
      "\n",
      "Error - Updating weight to: [-0.2613600000000003, -0.13824]\n",
      "\n",
      "Error - Updating weight to: [-0.2620800000000003, -0.13906]\n",
      "\n",
      "Error - Updating weight to: [-0.2630000000000003, -0.13865999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.2637800000000003, -0.13951999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.2637800000000003, -0.13951999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.2637800000000003, -0.13951999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.2637800000000003, -0.13951999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.2645000000000003, -0.14033999999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.26542000000000027, -0.13993999999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.26620000000000027, -0.14079999999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.26620000000000027, -0.14079999999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.26620000000000027, -0.14079999999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.26620000000000027, -0.14079999999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.26692000000000027, -0.14161999999999994]\n",
      "\n",
      "Error - Updating weight to: [-0.26784000000000024, -0.14121999999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.26862000000000025, -0.14207999999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.26862000000000025, -0.14207999999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.26862000000000025, -0.14207999999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.26862000000000025, -0.14207999999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.26934000000000025, -0.14289999999999992]\n",
      "\n",
      "Error - Updating weight to: [-0.2702600000000002, -0.1424999999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.2710400000000002, -0.1433599999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.2710400000000002, -0.1433599999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.2710400000000002, -0.1433599999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.2710400000000002, -0.1433599999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.2717600000000002, -0.1441799999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.2726800000000002, -0.14377999999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.2734600000000002, -0.14463999999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.2734600000000002, -0.14463999999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.2734600000000002, -0.14463999999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.2734600000000002, -0.14463999999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.2741800000000002, -0.14545999999999987]\n",
      "\n",
      "Error - Updating weight to: [-0.2751000000000002, -0.14505999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.2758800000000002, -0.14591999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.2758800000000002, -0.14591999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.2758800000000002, -0.14591999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.2758800000000002, -0.14591999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.2766000000000002, -0.14673999999999984]\n",
      "\n",
      "Error - Updating weight to: [-0.27752000000000016, -0.14633999999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.27830000000000016, -0.14719999999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.27830000000000016, -0.14719999999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.27830000000000016, -0.14719999999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.27830000000000016, -0.14719999999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.27902000000000016, -0.14801999999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.27994000000000013, -0.1476199999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.28072000000000014, -0.1484799999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.28072000000000014, -0.1484799999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.28072000000000014, -0.1484799999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.28072000000000014, -0.1484799999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.28144000000000013, -0.1492999999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.2823600000000001, -0.14889999999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.2831400000000001, -0.14975999999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.2831400000000001, -0.14975999999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.2831400000000001, -0.14975999999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.2831400000000001, -0.14975999999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.2838600000000001, -0.15057999999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.2847800000000001, -0.15017999999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.2855600000000001, -0.15103999999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.2855600000000001, -0.15103999999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.2855600000000001, -0.15103999999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.2855600000000001, -0.15103999999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.2862800000000001, -0.15185999999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.28720000000000007, -0.15145999999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.28798000000000007, -0.15231999999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.28798000000000007, -0.15231999999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.28798000000000007, -0.15231999999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.28798000000000007, -0.15231999999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.28870000000000007, -0.15313999999999972]\n",
      "\n",
      "Error - Updating weight to: [-0.28962000000000004, -0.1527399999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.29040000000000005, -0.1535999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.29040000000000005, -0.1535999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.29040000000000005, -0.1535999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.29040000000000005, -0.1535999999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.29112000000000005, -0.1544199999999997]\n",
      "\n",
      "Error - Updating weight to: [-0.29204, -0.15401999999999968]\n",
      "\n",
      "Error - Updating weight to: [-0.29282, -0.15487999999999968]\n",
      "\n",
      "Error - Updating weight to: [-0.29282, -0.15487999999999968]\n",
      "\n",
      "Error - Updating weight to: [-0.29282, -0.15487999999999968]\n",
      "\n",
      "Error - Updating weight to: [-0.29282, -0.15487999999999968]\n",
      "\n",
      "Error - Updating weight to: [-0.29354, -0.15569999999999967]\n",
      "\n",
      "Error - Updating weight to: [-0.29446, -0.15529999999999966]\n",
      "\n",
      "Error - Updating weight to: [-0.29524, -0.15615999999999966]\n",
      "\n",
      "Error - Updating weight to: [-0.29524, -0.15615999999999966]\n",
      "\n",
      "Error - Updating weight to: [-0.29524, -0.15615999999999966]\n",
      "\n",
      "Error - Updating weight to: [-0.29524, -0.15615999999999966]\n",
      "\n",
      "Error - Updating weight to: [-0.29596, -0.15697999999999965]\n",
      "\n",
      "Error - Updating weight to: [-0.29688, -0.15657999999999964]\n",
      "\n",
      "Error - Updating weight to: [-0.29766, -0.15743999999999964]\n",
      "\n",
      "Error - Updating weight to: [-0.29766, -0.15743999999999964]\n",
      "\n",
      "Error - Updating weight to: [-0.29766, -0.15743999999999964]\n",
      "\n",
      "Error - Updating weight to: [-0.29766, -0.15743999999999964]\n",
      "\n",
      "Error - Updating weight to: [-0.29838, -0.15825999999999962]\n",
      "\n",
      "Error - Updating weight to: [-0.29929999999999995, -0.1578599999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30007999999999996, -0.1587199999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30007999999999996, -0.1587199999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30007999999999996, -0.1587199999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30007999999999996, -0.1587199999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30079999999999996, -0.1595399999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30171999999999993, -0.1591399999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30249999999999994, -0.1599999999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30249999999999994, -0.1599999999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30249999999999994, -0.1599999999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30249999999999994, -0.1599999999999996]\n",
      "\n",
      "Error - Updating weight to: [-0.30321999999999993, -0.16081999999999957]\n",
      "\n",
      "Error - Updating weight to: [-0.3041399999999999, -0.16041999999999956]\n",
      "\n",
      "Error - Updating weight to: [-0.3049199999999999, -0.16127999999999956]\n",
      "\n",
      "Error - Updating weight to: [-0.3049199999999999, -0.16127999999999956]\n",
      "\n",
      "Error - Updating weight to: [-0.3049199999999999, -0.16127999999999956]\n",
      "\n",
      "Error - Updating weight to: [-0.3049199999999999, -0.16127999999999956]\n",
      "\n",
      "Error - Updating weight to: [-0.3056399999999999, -0.16209999999999955]\n",
      "\n",
      "Error - Updating weight to: [-0.3065599999999999, -0.16169999999999954]\n",
      "\n",
      "Error - Updating weight to: [-0.3073399999999999, -0.16255999999999954]\n",
      "\n",
      "Error - Updating weight to: [-0.3073399999999999, -0.16255999999999954]\n",
      "\n",
      "Error - Updating weight to: [-0.3073399999999999, -0.16255999999999954]\n",
      "\n",
      "Error - Updating weight to: [-0.3073399999999999, -0.16255999999999954]\n",
      "\n",
      "Error - Updating weight to: [-0.3080599999999999, -0.16337999999999953]\n",
      "\n",
      "Error - Updating weight to: [-0.30897999999999987, -0.16297999999999951]\n",
      "\n",
      "Error - Updating weight to: [-0.30975999999999987, -0.1638399999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.30975999999999987, -0.1638399999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.30975999999999987, -0.1638399999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.30975999999999987, -0.1638399999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.31047999999999987, -0.1646599999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.31139999999999984, -0.1642599999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.31217999999999985, -0.1651199999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.31217999999999985, -0.1651199999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.31217999999999985, -0.1651199999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.31217999999999985, -0.1651199999999995]\n",
      "\n",
      "Error - Updating weight to: [-0.31289999999999984, -0.16593999999999948]\n",
      "\n",
      "Error - Updating weight to: [-0.3138199999999998, -0.16553999999999947]\n",
      "\n",
      "Error - Updating weight to: [-0.3145999999999998, -0.16639999999999947]\n",
      "\n",
      "Error - Updating weight to: [-0.3145999999999998, -0.16639999999999947]\n",
      "\n",
      "Error - Updating weight to: [-0.3145999999999998, -0.16639999999999947]\n",
      "\n",
      "Error - Updating weight to: [-0.3145999999999998, -0.16639999999999947]\n",
      "\n",
      "Error - Updating weight to: [-0.3153199999999998, -0.16721999999999945]\n",
      "\n",
      "Error - Updating weight to: [-0.3162399999999998, -0.16681999999999944]\n",
      "\n",
      "Error - Updating weight to: [-0.3170199999999998, -0.16767999999999944]\n",
      "\n",
      "Error - Updating weight to: [-0.3170199999999998, -0.16767999999999944]\n",
      "\n",
      "Error - Updating weight to: [-0.3170199999999998, -0.16767999999999944]\n",
      "\n",
      "Error - Updating weight to: [-0.3170199999999998, -0.16767999999999944]\n",
      "\n",
      "Error - Updating weight to: [-0.3177399999999998, -0.16849999999999943]\n",
      "\n",
      "Error - Updating weight to: [-0.3186599999999998, -0.16809999999999942]\n",
      "\n",
      "Error - Updating weight to: [-0.3194399999999998, -0.16895999999999942]\n",
      "\n",
      "Error - Updating weight to: [-0.3194399999999998, -0.16895999999999942]\n",
      "\n",
      "Error - Updating weight to: [-0.3194399999999998, -0.16895999999999942]\n",
      "\n",
      "Error - Updating weight to: [-0.3194399999999998, -0.16895999999999942]\n",
      "\n",
      "Error - Updating weight to: [-0.3201599999999998, -0.1697799999999994]\n",
      "\n",
      "Error - Updating weight to: [-0.32107999999999975, -0.1693799999999994]\n",
      "\n",
      "Error - Updating weight to: [-0.32185999999999976, -0.1702399999999994]\n",
      "\n",
      "Error - Updating weight to: [-0.32185999999999976, -0.1702399999999994]\n",
      "\n",
      "Error - Updating weight to: [-0.32185999999999976, -0.1702399999999994]\n",
      "\n",
      "Error - Updating weight to: [-0.32185999999999976, -0.1702399999999994]\n",
      "\n",
      "Error - Updating weight to: [-0.32257999999999976, -0.17105999999999938]\n",
      "\n",
      "Error - Updating weight to: [-0.32349999999999973, -0.17065999999999937]\n",
      "\n",
      "Error - Updating weight to: [-0.32427999999999974, -0.17151999999999937]\n",
      "\n",
      "Error - Updating weight to: [-0.32427999999999974, -0.17151999999999937]\n",
      "\n",
      "Error - Updating weight to: [-0.32427999999999974, -0.17151999999999937]\n",
      "\n",
      "Error - Updating weight to: [-0.32427999999999974, -0.17151999999999937]\n",
      "\n",
      "Error - Updating weight to: [-0.32499999999999973, -0.17233999999999935]\n",
      "\n",
      "Error - Updating weight to: [-0.3259199999999997, -0.17193999999999934]\n",
      "\n",
      "Error - Updating weight to: [-0.3266999999999997, -0.17279999999999934]\n",
      "\n",
      "Error - Updating weight to: [-0.3266999999999997, -0.17279999999999934]\n",
      "\n",
      "Error - Updating weight to: [-0.3266999999999997, -0.17279999999999934]\n",
      "\n",
      "Error - Updating weight to: [-0.3266999999999997, -0.17279999999999934]\n",
      "\n",
      "Error - Updating weight to: [-0.3274199999999997, -0.17361999999999933]\n",
      "\n",
      "Error - Updating weight to: [-0.3283399999999997, -0.17321999999999932]\n",
      "\n",
      "Error - Updating weight to: [-0.3291199999999997, -0.17407999999999932]\n",
      "\n",
      "Error - Updating weight to: [-0.3291199999999997, -0.17407999999999932]\n",
      "\n",
      "Error - Updating weight to: [-0.3291199999999997, -0.17407999999999932]\n",
      "\n",
      "Error - Updating weight to: [-0.3291199999999997, -0.17407999999999932]\n",
      "\n",
      "Error - Updating weight to: [-0.3298399999999997, -0.1748999999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.33075999999999967, -0.1744999999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.33153999999999967, -0.1753599999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.33153999999999967, -0.1753599999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.33153999999999967, -0.1753599999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.33153999999999967, -0.1753599999999993]\n",
      "\n",
      "Error - Updating weight to: [-0.33225999999999967, -0.17617999999999928]\n",
      "\n",
      "Error - Updating weight to: [-0.33317999999999964, -0.17577999999999927]\n",
      "\n",
      "Error - Updating weight to: [-0.33395999999999965, -0.17663999999999927]\n",
      "\n",
      "Error - Updating weight to: [-0.33395999999999965, -0.17663999999999927]\n",
      "\n",
      "Error - Updating weight to: [-0.33395999999999965, -0.17663999999999927]\n",
      "\n",
      "Error - Updating weight to: [-0.33395999999999965, -0.17663999999999927]\n",
      "\n",
      "Error - Updating weight to: [-0.33467999999999964, -0.17745999999999926]\n",
      "\n",
      "Error - Updating weight to: [-0.3355999999999996, -0.17705999999999925]\n",
      "\n",
      "Error - Updating weight to: [-0.3363799999999996, -0.17791999999999925]\n",
      "\n",
      "Error - Updating weight to: [-0.3363799999999996, -0.17791999999999925]\n",
      "\n",
      "Error - Updating weight to: [-0.3363799999999996, -0.17791999999999925]\n",
      "\n",
      "Error - Updating weight to: [-0.3363799999999996, -0.17791999999999925]\n",
      "\n",
      "Error - Updating weight to: [-0.3370999999999996, -0.17873999999999923]\n",
      "\n",
      "Error - Updating weight to: [-0.3380199999999996, -0.17833999999999922]\n",
      "\n",
      "Error - Updating weight to: [-0.3387999999999996, -0.17919999999999922]\n",
      "\n",
      "Error - Updating weight to: [-0.3387999999999996, -0.17919999999999922]\n",
      "\n",
      "Error - Updating weight to: [-0.3387999999999996, -0.17919999999999922]\n",
      "\n",
      "Error - Updating weight to: [-0.3387999999999996, -0.17919999999999922]\n",
      "\n",
      "Error - Updating weight to: [-0.3395199999999996, -0.1800199999999992]\n",
      "\n",
      "Error - Updating weight to: [-0.3404399999999996, -0.1796199999999992]\n",
      "\n",
      "Error - Updating weight to: [-0.3412199999999996, -0.1804799999999992]\n",
      "\n",
      "Error - Updating weight to: [-0.3412199999999996, -0.1804799999999992]\n",
      "\n",
      "Error - Updating weight to: [-0.3412199999999996, -0.1804799999999992]\n",
      "\n",
      "Error - Updating weight to: [-0.3412199999999996, -0.1804799999999992]\n",
      "\n",
      "Error - Updating weight to: [-0.3419399999999996, -0.18129999999999918]\n",
      "\n",
      "Error - Updating weight to: [-0.34285999999999955, -0.18089999999999917]\n",
      "\n",
      "Error - Updating weight to: [-0.34363999999999956, -0.18175999999999917]\n",
      "\n",
      "Error - Updating weight to: [-0.34363999999999956, -0.18175999999999917]\n",
      "\n",
      "Error - Updating weight to: [-0.34363999999999956, -0.18175999999999917]\n",
      "\n",
      "Error - Updating weight to: [-0.34363999999999956, -0.18175999999999917]\n",
      "\n",
      "Error - Updating weight to: [-0.34435999999999956, -0.18257999999999916]\n",
      "\n",
      "Error - Updating weight to: [-0.34527999999999953, -0.18217999999999915]\n",
      "\n",
      "Error - Updating weight to: [-0.34605999999999953, -0.18303999999999915]\n",
      "\n",
      "Error - Updating weight to: [-0.34605999999999953, -0.18303999999999915]\n",
      "\n",
      "Error - Updating weight to: [-0.34605999999999953, -0.18303999999999915]\n",
      "\n",
      "Error - Updating weight to: [-0.34605999999999953, -0.18303999999999915]\n",
      "\n",
      "Error - Updating weight to: [-0.34677999999999953, -0.18385999999999914]\n",
      "\n",
      "Error - Updating weight to: [-0.3476999999999995, -0.18345999999999912]\n",
      "\n",
      "Error - Updating weight to: [-0.3484799999999995, -0.18431999999999912]\n",
      "\n",
      "Error - Updating weight to: [-0.3484799999999995, -0.18431999999999912]\n",
      "\n",
      "Error - Updating weight to: [-0.3484799999999995, -0.18431999999999912]\n",
      "\n",
      "Error - Updating weight to: [-0.3484799999999995, -0.18431999999999912]\n",
      "\n",
      "Error - Updating weight to: [-0.3491999999999995, -0.1851399999999991]\n",
      "\n",
      "Error - Updating weight to: [-0.3501199999999995, -0.1847399999999991]\n",
      "\n",
      "Error - Updating weight to: [-0.3508999999999995, -0.1855999999999991]\n",
      "\n",
      "Error - Updating weight to: [-0.3508999999999995, -0.1855999999999991]\n",
      "\n",
      "Error - Updating weight to: [-0.3508999999999995, -0.1855999999999991]\n",
      "\n",
      "Error - Updating weight to: [-0.3508999999999995, -0.1855999999999991]\n",
      "\n",
      "Error - Updating weight to: [-0.3516199999999995, -0.1864199999999991]\n",
      "\n",
      "Error - Updating weight to: [-0.35253999999999946, -0.18601999999999907]\n",
      "\n",
      "Error - Updating weight to: [-0.35331999999999947, -0.18687999999999907]\n",
      "\n",
      "Error - Updating weight to: [-0.35331999999999947, -0.18687999999999907]\n",
      "\n",
      "Error - Updating weight to: [-0.35331999999999947, -0.18687999999999907]\n",
      "\n",
      "Error - Updating weight to: [-0.35331999999999947, -0.18687999999999907]\n",
      "\n",
      "Error - Updating weight to: [-0.35403999999999947, -0.18769999999999906]\n",
      "\n",
      "Error - Updating weight to: [-0.35495999999999944, -0.18729999999999905]\n",
      "\n",
      "Error - Updating weight to: [-0.35573999999999945, -0.18815999999999905]\n",
      "\n",
      "Error - Updating weight to: [-0.35573999999999945, -0.18815999999999905]\n",
      "\n",
      "Error - Updating weight to: [-0.35573999999999945, -0.18815999999999905]\n",
      "\n",
      "Error - Updating weight to: [-0.35573999999999945, -0.18815999999999905]\n",
      "\n",
      "Error - Updating weight to: [-0.35645999999999944, -0.18897999999999904]\n",
      "\n",
      "Error - Updating weight to: [-0.3573799999999994, -0.18857999999999903]\n",
      "\n",
      "Error - Updating weight to: [-0.3581599999999994, -0.18943999999999903]\n",
      "\n",
      "Error - Updating weight to: [-0.3581599999999994, -0.18943999999999903]\n",
      "\n",
      "Error - Updating weight to: [-0.3581599999999994, -0.18943999999999903]\n",
      "\n",
      "Error - Updating weight to: [-0.3581599999999994, -0.18943999999999903]\n",
      "\n",
      "Error - Updating weight to: [-0.3588799999999994, -0.190259999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.3597999999999994, -0.189859999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.3605799999999994, -0.190719999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.3605799999999994, -0.190719999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.3605799999999994, -0.190719999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.3605799999999994, -0.190719999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.3612999999999994, -0.191539999999999]\n",
      "\n",
      "Error - Updating weight to: [-0.3622199999999994, -0.19113999999999898]\n",
      "\n",
      "Error - Updating weight to: [-0.3629999999999994, -0.19199999999999898]\n",
      "\n",
      "Error - Updating weight to: [-0.3629999999999994, -0.19199999999999898]\n",
      "\n",
      "Error - Updating weight to: [-0.3629999999999994, -0.19199999999999898]\n",
      "\n",
      "Error - Updating weight to: [-0.3629999999999994, -0.19199999999999898]\n",
      "\n",
      "Error - Updating weight to: [-0.3637199999999994, -0.19281999999999896]\n",
      "\n",
      "Error - Updating weight to: [-0.36463999999999935, -0.19241999999999895]\n",
      "\n",
      "Error - Updating weight to: [-0.36541999999999936, -0.19327999999999895]\n",
      "\n",
      "Error - Updating weight to: [-0.36541999999999936, -0.19327999999999895]\n",
      "\n",
      "Error - Updating weight to: [-0.36541999999999936, -0.19327999999999895]\n",
      "\n",
      "Error - Updating weight to: [-0.36541999999999936, -0.19327999999999895]\n",
      "\n",
      "Error - Updating weight to: [-0.36613999999999935, -0.19409999999999894]\n",
      "\n",
      "Error - Updating weight to: [-0.36705999999999933, -0.19369999999999893]\n",
      "\n",
      "Error - Updating weight to: [-0.36783999999999933, -0.19455999999999893]\n",
      "\n",
      "Error - Updating weight to: [-0.36783999999999933, -0.19455999999999893]\n",
      "\n",
      "Error - Updating weight to: [-0.36783999999999933, -0.19455999999999893]\n",
      "\n",
      "Error - Updating weight to: [-0.36783999999999933, -0.19455999999999893]\n",
      "\n",
      "Error - Updating weight to: [-0.36855999999999933, -0.19537999999999892]\n",
      "\n",
      "Error - Updating weight to: [-0.3694799999999993, -0.1949799999999989]\n",
      "\n",
      "Error - Updating weight to: [-0.3702599999999993, -0.1958399999999989]\n",
      "\n",
      "Error - Updating weight to: [-0.3702599999999993, -0.1958399999999989]\n",
      "\n",
      "Error - Updating weight to: [-0.3702599999999993, -0.1958399999999989]\n",
      "\n",
      "Error - Updating weight to: [-0.3702599999999993, -0.1958399999999989]\n",
      "\n",
      "Error - Updating weight to: [-0.3709799999999993, -0.1966599999999989]\n",
      "\n",
      "Error - Updating weight to: [-0.3718999999999993, -0.19625999999999888]\n",
      "\n",
      "Error - Updating weight to: [-0.3726799999999993, -0.19711999999999888]\n",
      "\n",
      "Error - Updating weight to: [-0.3726799999999993, -0.19711999999999888]\n",
      "\n",
      "Error - Updating weight to: [-0.3726799999999993, -0.19711999999999888]\n",
      "\n",
      "Error - Updating weight to: [-0.3726799999999993, -0.19711999999999888]\n",
      "\n",
      "Error - Updating weight to: [-0.3733999999999993, -0.19793999999999887]\n",
      "\n",
      "Error - Updating weight to: [-0.37431999999999926, -0.19753999999999886]\n",
      "\n",
      "Error - Updating weight to: [-0.37509999999999927, -0.19839999999999886]\n",
      "\n",
      "Error - Updating weight to: [-0.37509999999999927, -0.19839999999999886]\n",
      "\n",
      "Error - Updating weight to: [-0.37509999999999927, -0.19839999999999886]\n",
      "\n",
      "Error - Updating weight to: [-0.37509999999999927, -0.19839999999999886]\n",
      "\n",
      "Error - Updating weight to: [-0.37581999999999927, -0.19921999999999884]\n",
      "\n",
      "Error - Updating weight to: [-0.37673999999999924, -0.19881999999999883]\n",
      "\n",
      "Error - Updating weight to: [-0.37751999999999925, -0.19967999999999883]\n",
      "\n",
      "Error - Updating weight to: [-0.37751999999999925, -0.19967999999999883]\n",
      "\n",
      "Error - Updating weight to: [-0.37751999999999925, -0.19967999999999883]\n",
      "\n",
      "Error - Updating weight to: [-0.37751999999999925, -0.19967999999999883]\n",
      "\n",
      "Error - Updating weight to: [-0.37823999999999924, -0.20049999999999882]\n",
      "\n",
      "Error - Updating weight to: [-0.3791599999999992, -0.2000999999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.3799399999999992, -0.2009599999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.3799399999999992, -0.2009599999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.3799399999999992, -0.2009599999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.3799399999999992, -0.2009599999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.3806599999999992, -0.2017799999999988]\n",
      "\n",
      "Error - Updating weight to: [-0.3815799999999992, -0.20137999999999878]\n",
      "\n",
      "Error - Updating weight to: [-0.3823599999999992, -0.20223999999999878]\n",
      "\n",
      "Error - Updating weight to: [-0.3823599999999992, -0.20223999999999878]\n",
      "\n",
      "Error - Updating weight to: [-0.3823599999999992, -0.20223999999999878]\n",
      "\n",
      "Error - Updating weight to: [-0.3823599999999992, -0.20223999999999878]\n",
      "\n",
      "Error - Updating weight to: [-0.3830799999999992, -0.20305999999999877]\n",
      "\n",
      "Error - Updating weight to: [-0.3839999999999992, -0.20265999999999876]\n",
      "\n",
      "Error - Updating weight to: [-0.3847799999999992, -0.20351999999999876]\n",
      "\n",
      "Error - Updating weight to: [-0.3847799999999992, -0.20351999999999876]\n",
      "\n",
      "Error - Updating weight to: [-0.3847799999999992, -0.20351999999999876]\n",
      "\n",
      "Error - Updating weight to: [-0.3847799999999992, -0.20351999999999876]\n",
      "\n",
      "Error - Updating weight to: [-0.3854999999999992, -0.20433999999999874]\n",
      "\n",
      "Error - Updating weight to: [-0.38641999999999915, -0.20393999999999873]\n",
      "\n",
      "Error - Updating weight to: [-0.38719999999999916, -0.20479999999999873]\n",
      "\n",
      "Error - Updating weight to: [-0.38719999999999916, -0.20479999999999873]\n",
      "\n",
      "Error - Updating weight to: [-0.38719999999999916, -0.20479999999999873]\n",
      "\n",
      "Error - Updating weight to: [-0.38719999999999916, -0.20479999999999873]\n",
      "\n",
      "Error - Updating weight to: [-0.38791999999999915, -0.20561999999999872]\n",
      "\n",
      "Error - Updating weight to: [-0.38883999999999913, -0.2052199999999987]\n",
      "\n",
      "Error - Updating weight to: [-0.38961999999999913, -0.2060799999999987]\n",
      "\n",
      "Error - Updating weight to: [-0.38961999999999913, -0.2060799999999987]\n",
      "\n",
      "Error - Updating weight to: [-0.38961999999999913, -0.2060799999999987]\n",
      "\n",
      "Error - Updating weight to: [-0.38961999999999913, -0.2060799999999987]\n",
      "\n",
      "Error - Updating weight to: [-0.39033999999999913, -0.2068999999999987]\n",
      "\n",
      "Error - Updating weight to: [-0.3912599999999991, -0.20649999999999868]\n",
      "\n",
      "Error - Updating weight to: [-0.3920399999999991, -0.20735999999999868]\n",
      "\n",
      "Error - Updating weight to: [-0.3920399999999991, -0.20735999999999868]\n",
      "\n",
      "Error - Updating weight to: [-0.3920399999999991, -0.20735999999999868]\n",
      "\n",
      "Error - Updating weight to: [-0.3920399999999991, -0.20735999999999868]\n",
      "\n",
      "Error - Updating weight to: [-0.3927599999999991, -0.20817999999999867]\n",
      "\n",
      "Error - Updating weight to: [-0.3936799999999991, -0.20777999999999866]\n",
      "\n",
      "Error - Updating weight to: [-0.3944599999999991, -0.20863999999999866]\n",
      "\n",
      "Error - Updating weight to: [-0.3944599999999991, -0.20863999999999866]\n",
      "\n",
      "Error - Updating weight to: [-0.3944599999999991, -0.20863999999999866]\n",
      "\n",
      "Error - Updating weight to: [-0.3944599999999991, -0.20863999999999866]\n",
      "\n",
      "Error - Updating weight to: [-0.3951799999999991, -0.20945999999999865]\n",
      "\n",
      "Error - Updating weight to: [-0.39609999999999906, -0.20905999999999864]\n",
      "\n",
      "Error - Updating weight to: [-0.39687999999999907, -0.20991999999999864]\n",
      "\n",
      "Error - Updating weight to: [-0.39687999999999907, -0.20991999999999864]\n",
      "\n",
      "Error - Updating weight to: [-0.39687999999999907, -0.20991999999999864]\n",
      "\n",
      "Error - Updating weight to: [-0.39687999999999907, -0.20991999999999864]\n",
      "\n",
      "Error - Updating weight to: [-0.39759999999999907, -0.21073999999999862]\n",
      "\n",
      "Error - Updating weight to: [-0.39851999999999904, -0.2103399999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.39929999999999904, -0.2111999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.39929999999999904, -0.2111999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.39929999999999904, -0.2111999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.39929999999999904, -0.2111999999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.40001999999999904, -0.2120199999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.400939999999999, -0.2116199999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.401719999999999, -0.2124799999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.401719999999999, -0.2124799999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.401719999999999, -0.2124799999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.401719999999999, -0.2124799999999986]\n",
      "\n",
      "Error - Updating weight to: [-0.402439999999999, -0.21329999999999857]\n",
      "\n",
      "Error - Updating weight to: [-0.403359999999999, -0.21289999999999856]\n",
      "\n",
      "Error - Updating weight to: [-0.404139999999999, -0.21375999999999856]\n",
      "\n",
      "Error - Updating weight to: [-0.404139999999999, -0.21375999999999856]\n",
      "\n",
      "Error - Updating weight to: [-0.404139999999999, -0.21375999999999856]\n",
      "\n",
      "Error - Updating weight to: [-0.404139999999999, -0.21375999999999856]\n",
      "\n",
      "Error - Updating weight to: [-0.404859999999999, -0.21457999999999855]\n",
      "\n",
      "Error - Updating weight to: [-0.405779999999999, -0.21417999999999854]\n",
      "\n",
      "Error - Updating weight to: [-0.405779999999999, -0.21417999999999854]\n",
      "\n",
      "Error - Updating weight to: [-0.405779999999999, -0.21417999999999854]\n",
      "\n",
      "Error - Updating weight to: [-0.405779999999999, -0.21417999999999854]\n",
      "\n",
      "Error - Updating weight to: [-0.405779999999999, -0.21417999999999854]\n",
      "\n",
      "Error - Updating weight to: [-0.406499999999999, -0.21499999999999853]\n",
      "\n",
      "Error - Updating weight to: [-0.40741999999999895, -0.21459999999999851]\n",
      "\n",
      "Error - Updating weight to: [-0.40741999999999895, -0.21459999999999851]\n",
      "\n",
      "Error - Updating weight to: [-0.40741999999999895, -0.21459999999999851]\n",
      "\n",
      "Error - Updating weight to: [-0.40741999999999895, -0.21459999999999851]\n",
      "\n",
      "Error - Updating weight to: [-0.40741999999999895, -0.21459999999999851]\n",
      "\n",
      "Error - Updating weight to: [-0.40813999999999895, -0.2154199999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.4090599999999989, -0.2150199999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.4090599999999989, -0.2150199999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.4090599999999989, -0.2150199999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.4090599999999989, -0.2150199999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.4090599999999989, -0.2150199999999985]\n",
      "\n",
      "Error - Updating weight to: [-0.4097799999999989, -0.21583999999999848]\n",
      "\n",
      "Error - Updating weight to: [-0.4106999999999989, -0.21543999999999847]\n",
      "\n",
      "Error - Updating weight to: [-0.4106999999999989, -0.21543999999999847]\n",
      "\n",
      "Error - Updating weight to: [-0.4106999999999989, -0.21543999999999847]\n",
      "\n",
      "Error - Updating weight to: [-0.4106999999999989, -0.21543999999999847]\n",
      "\n",
      "Error - Updating weight to: [-0.4106999999999989, -0.21543999999999847]\n",
      "\n",
      "Error - Updating weight to: [-0.4114199999999989, -0.21625999999999845]\n",
      "\n",
      "Error - Updating weight to: [-0.4123399999999989, -0.21585999999999844]\n",
      "\n",
      "Error - Updating weight to: [-0.4123399999999989, -0.21585999999999844]\n",
      "\n",
      "Error - Updating weight to: [-0.4123399999999989, -0.21585999999999844]\n",
      "\n",
      "Error - Updating weight to: [-0.4123399999999989, -0.21585999999999844]\n",
      "\n",
      "Error - Updating weight to: [-0.4123399999999989, -0.21585999999999844]\n",
      "\n",
      "Error - Updating weight to: [-0.4130599999999989, -0.21667999999999843]\n",
      "\n",
      "Error - Updating weight to: [-0.41397999999999885, -0.21627999999999842]\n",
      "\n",
      "Error - Updating weight to: [-0.41397999999999885, -0.21627999999999842]\n",
      "\n",
      "Error - Updating weight to: [-0.41397999999999885, -0.21627999999999842]\n",
      "\n",
      "Error - Updating weight to: [-0.41397999999999885, -0.21627999999999842]\n",
      "\n",
      "Error - Updating weight to: [-0.41397999999999885, -0.21627999999999842]\n",
      "\n",
      "Error - Updating weight to: [-0.41469999999999885, -0.2170999999999984]\n",
      "\n",
      "Error - Updating weight to: [-0.4156199999999988, -0.2166999999999984]\n",
      "\n",
      "Error - Updating weight to: [-0.4156199999999988, -0.2166999999999984]\n",
      "\n",
      "Error - Updating weight to: [-0.4156199999999988, -0.2166999999999984]\n",
      "\n",
      "Error - Updating weight to: [-0.4156199999999988, -0.2166999999999984]\n",
      "\n",
      "Error - Updating weight to: [-0.4156199999999988, -0.2166999999999984]\n",
      "\n",
      "Error - Updating weight to: [-0.4163399999999988, -0.21751999999999838]\n",
      "\n",
      "Error - Updating weight to: [-0.4172599999999988, -0.21711999999999837]\n",
      "\n",
      "Error - Updating weight to: [-0.4172599999999988, -0.21711999999999837]\n",
      "\n",
      "Error - Updating weight to: [-0.4172599999999988, -0.21711999999999837]\n",
      "\n",
      "Error - Updating weight to: [-0.4172599999999988, -0.21711999999999837]\n",
      "\n",
      "Error - Updating weight to: [-0.4172599999999988, -0.21711999999999837]\n",
      "\n",
      "Error - Updating weight to: [-0.4179799999999988, -0.21793999999999836]\n",
      "\n",
      "Error - Updating weight to: [-0.4188999999999988, -0.21753999999999835]\n",
      "\n",
      "Error - Updating weight to: [-0.4188999999999988, -0.21753999999999835]\n",
      "\n",
      "Error - Updating weight to: [-0.4188999999999988, -0.21753999999999835]\n",
      "\n",
      "Error - Updating weight to: [-0.4188999999999988, -0.21753999999999835]\n",
      "\n",
      "Error - Updating weight to: [-0.4188999999999988, -0.21753999999999835]\n",
      "\n",
      "Error - Updating weight to: [-0.41961999999999877, -0.21835999999999833]\n",
      "\n",
      "Error - Updating weight to: [-0.42053999999999875, -0.21795999999999832]\n",
      "\n",
      "Error - Updating weight to: [-0.42053999999999875, -0.21795999999999832]\n",
      "\n",
      "Error - Updating weight to: [-0.42053999999999875, -0.21795999999999832]\n",
      "\n",
      "Error - Updating weight to: [-0.42053999999999875, -0.21795999999999832]\n",
      "\n",
      "Error - Updating weight to: [-0.42053999999999875, -0.21795999999999832]\n",
      "\n",
      "Error - Updating weight to: [-0.42053999999999875, -0.21795999999999832]\n",
      "\n",
      "Error - Updating weight to: [-0.4214599999999987, -0.2175599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4214599999999987, -0.2175599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4214599999999987, -0.2175599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4214599999999987, -0.2175599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4214599999999987, -0.2175599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4214599999999987, -0.2175599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4223799999999987, -0.2171599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4223799999999987, -0.2171599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4223799999999987, -0.2171599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4223799999999987, -0.2171599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4223799999999987, -0.2171599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4223799999999987, -0.2171599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4232999999999987, -0.2167599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4232999999999987, -0.2167599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4232999999999987, -0.2167599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4232999999999987, -0.2167599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4232999999999987, -0.2167599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.4232999999999987, -0.2167599999999983]\n",
      "\n",
      "Error - Updating weight to: [-0.42421999999999865, -0.21635999999999828]\n",
      "\n",
      "Error - Updating weight to: [-0.42421999999999865, -0.21635999999999828]\n",
      "\n",
      "Error - Updating weight to: [-0.42421999999999865, -0.21635999999999828]\n",
      "\n",
      "Error - Updating weight to: [-0.42421999999999865, -0.21635999999999828]\n",
      "\n",
      "Error - Updating weight to: [-0.42421999999999865, -0.21635999999999828]\n",
      "\n",
      "Error - Updating weight to: [-0.42421999999999865, -0.21635999999999828]\n",
      "\n",
      "Error - Updating weight to: [-0.42513999999999863, -0.21595999999999826]\n",
      "\n",
      "Error - Updating weight to: [-0.42513999999999863, -0.21595999999999826]\n",
      "\n",
      "Error - Updating weight to: [-0.42513999999999863, -0.21595999999999826]\n",
      "\n",
      "Error - Updating weight to: [-0.42513999999999863, -0.21595999999999826]\n",
      "\n",
      "Error - Updating weight to: [-0.42513999999999863, -0.21595999999999826]\n",
      "\n",
      "Error - Updating weight to: [-0.42513999999999863, -0.21595999999999826]\n",
      "\n",
      "Error - Updating weight to: [-0.4260599999999986, -0.21555999999999825]\n",
      "\n",
      "Error - Updating weight to: [-0.4260599999999986, -0.21555999999999825]\n",
      "\n",
      "Error - Updating weight to: [-0.4260599999999986, -0.21555999999999825]\n",
      "\n",
      "Error - Updating weight to: [-0.4260599999999986, -0.21555999999999825]\n",
      "\n",
      "Error - Updating weight to: [-0.4260599999999986, -0.21555999999999825]\n",
      "\n",
      "Error - Updating weight to: [-0.4260599999999986, -0.21555999999999825]\n",
      "\n",
      "Error - Updating weight to: [-0.4269799999999986, -0.21515999999999824]\n",
      "\n",
      "Error - Updating weight to: [-0.4269799999999986, -0.21515999999999824]\n",
      "\n",
      "Error - Updating weight to: [-0.4269799999999986, -0.21515999999999824]\n",
      "\n",
      "Error - Updating weight to: [-0.4269799999999986, -0.21515999999999824]\n",
      "\n",
      "Error - Updating weight to: [-0.4269799999999986, -0.21515999999999824]\n",
      "\n",
      "Error - Updating weight to: [-0.4269799999999986, -0.21515999999999824]\n",
      "\n",
      "Error - Updating weight to: [-0.42789999999999856, -0.21475999999999823]\n",
      "\n",
      "Error - Updating weight to: [-0.42789999999999856, -0.21475999999999823]\n",
      "\n",
      "Error - Updating weight to: [-0.42789999999999856, -0.21475999999999823]\n",
      "\n",
      "Error - Updating weight to: [-0.42789999999999856, -0.21475999999999823]\n",
      "\n",
      "Error - Updating weight to: [-0.42789999999999856, -0.21475999999999823]\n",
      "\n",
      "Error - Updating weight to: [-0.42789999999999856, -0.21475999999999823]\n",
      "\n",
      "Error - Updating weight to: [-0.42881999999999854, -0.21435999999999822]\n",
      "\n",
      "Error - Updating weight to: [-0.42881999999999854, -0.21435999999999822]\n",
      "\n",
      "Error - Updating weight to: [-0.42881999999999854, -0.21435999999999822]\n",
      "\n",
      "Error - Updating weight to: [-0.42881999999999854, -0.21435999999999822]\n",
      "\n",
      "Error - Updating weight to: [-0.42881999999999854, -0.21435999999999822]\n",
      "\n",
      "Error - Updating weight to: [-0.42881999999999854, -0.21435999999999822]\n",
      "\n",
      "Error - Updating weight to: [-0.4297399999999985, -0.2139599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4297399999999985, -0.2139599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4297399999999985, -0.2139599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4297399999999985, -0.2139599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4297399999999985, -0.2139599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4297399999999985, -0.2139599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4306599999999985, -0.2135599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4306599999999985, -0.2135599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4306599999999985, -0.2135599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4306599999999985, -0.2135599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4306599999999985, -0.2135599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.4306599999999985, -0.2135599999999982]\n",
      "\n",
      "Error - Updating weight to: [-0.43157999999999846, -0.21315999999999818]\n",
      "\n",
      "Error - Updating weight to: [-0.43157999999999846, -0.21315999999999818]\n",
      "\n",
      "Error - Updating weight to: [-0.43157999999999846, -0.21315999999999818]\n",
      "\n",
      "Error - Updating weight to: [-0.43157999999999846, -0.21315999999999818]\n",
      "\n",
      "Error - Updating weight to: [-0.43157999999999846, -0.21315999999999818]\n",
      "\n",
      "Error - Updating weight to: [-0.43157999999999846, -0.21315999999999818]\n",
      "\n",
      "Error - Updating weight to: [-0.43249999999999844, -0.21275999999999817]\n",
      "\n",
      "Error - Updating weight to: [-0.43249999999999844, -0.21275999999999817]\n",
      "\n",
      "Error - Updating weight to: [-0.43249999999999844, -0.21275999999999817]\n",
      "\n",
      "Error - Updating weight to: [-0.43249999999999844, -0.21275999999999817]\n",
      "\n",
      "Error - Updating weight to: [-0.43249999999999844, -0.21275999999999817]\n",
      "\n",
      "Error - Updating weight to: [-0.43249999999999844, -0.21275999999999817]\n",
      "\n",
      "Error - Updating weight to: [-0.4334199999999984, -0.21235999999999816]\n",
      "\n",
      "Error - Updating weight to: [-0.4334199999999984, -0.21235999999999816]\n",
      "\n",
      "Error - Updating weight to: [-0.4334199999999984, -0.21235999999999816]\n",
      "\n",
      "Error - Updating weight to: [-0.4334199999999984, -0.21235999999999816]\n",
      "\n",
      "Error - Updating weight to: [-0.4334199999999984, -0.21235999999999816]\n",
      "\n",
      "Error - Updating weight to: [-0.4334199999999984, -0.21235999999999816]\n",
      "\n",
      "Error - Updating weight to: [-0.4343399999999984, -0.21195999999999815]\n",
      "\n",
      "Error - Updating weight to: [-0.4343399999999984, -0.21195999999999815]\n",
      "\n",
      "Error - Updating weight to: [-0.4343399999999984, -0.21195999999999815]\n",
      "\n",
      "Error - Updating weight to: [-0.4343399999999984, -0.21195999999999815]\n",
      "\n",
      "Error - Updating weight to: [-0.4343399999999984, -0.21195999999999815]\n",
      "\n",
      "Error - Updating weight to: [-0.4343399999999984, -0.21195999999999815]\n",
      "\n",
      "Error - Updating weight to: [-0.43525999999999837, -0.21155999999999814]\n",
      "\n",
      "Error - Updating weight to: [-0.43525999999999837, -0.21155999999999814]\n",
      "\n",
      "Error - Updating weight to: [-0.43525999999999837, -0.21155999999999814]\n",
      "\n",
      "Error - Updating weight to: [-0.43525999999999837, -0.21155999999999814]\n",
      "\n",
      "Error - Updating weight to: [-0.43525999999999837, -0.21155999999999814]\n",
      "\n",
      "Error - Updating weight to: [-0.43525999999999837, -0.21155999999999814]\n",
      "\n",
      "Error - Updating weight to: [-0.43617999999999835, -0.21115999999999813]\n",
      "\n",
      "Error - Updating weight to: [-0.43617999999999835, -0.21115999999999813]\n",
      "\n",
      "Error - Updating weight to: [-0.43617999999999835, -0.21115999999999813]\n",
      "\n",
      "Error - Updating weight to: [-0.43617999999999835, -0.21115999999999813]\n",
      "\n",
      "Error - Updating weight to: [-0.43617999999999835, -0.21115999999999813]\n",
      "\n",
      "Error - Updating weight to: [-0.43617999999999835, -0.21115999999999813]\n",
      "\n",
      "Error - Updating weight to: [-0.4370999999999983, -0.21075999999999812]\n",
      "\n",
      "Error - Updating weight to: [-0.4370999999999983, -0.21075999999999812]\n",
      "\n",
      "Error - Updating weight to: [-0.4370999999999983, -0.21075999999999812]\n",
      "\n",
      "Error - Updating weight to: [-0.4370999999999983, -0.21075999999999812]\n",
      "\n",
      "Error - Updating weight to: [-0.4370999999999983, -0.21075999999999812]\n",
      "\n",
      "Error - Updating weight to: [-0.4370999999999983, -0.21075999999999812]\n",
      "\n",
      "Error - Updating weight to: [-0.4380199999999983, -0.2103599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4380199999999983, -0.2103599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4380199999999983, -0.2103599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4380199999999983, -0.2103599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4380199999999983, -0.2103599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4380199999999983, -0.2103599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4389399999999983, -0.2099599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4389399999999983, -0.2099599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4389399999999983, -0.2099599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4389399999999983, -0.2099599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4389399999999983, -0.2099599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.4389399999999983, -0.2099599999999981]\n",
      "\n",
      "Error - Updating weight to: [-0.43985999999999825, -0.20955999999999808]\n",
      "\n",
      "Error - Updating weight to: [-0.43985999999999825, -0.20955999999999808]\n",
      "\n",
      "Error - Updating weight to: [-0.43985999999999825, -0.20955999999999808]\n",
      "\n",
      "Error - Updating weight to: [-0.43985999999999825, -0.20955999999999808]\n",
      "\n",
      "Error - Updating weight to: [-0.43985999999999825, -0.20955999999999808]\n",
      "\n",
      "Error - Updating weight to: [-0.43985999999999825, -0.20955999999999808]\n",
      "\n",
      "Error - Updating weight to: [-0.44077999999999823, -0.20915999999999807]\n",
      "\n",
      "Error - Updating weight to: [-0.44077999999999823, -0.20915999999999807]\n",
      "\n",
      "Error - Updating weight to: [-0.44077999999999823, -0.20915999999999807]\n",
      "\n",
      "Error - Updating weight to: [-0.44077999999999823, -0.20915999999999807]\n",
      "\n",
      "Error - Updating weight to: [-0.44077999999999823, -0.20915999999999807]\n",
      "\n",
      "Error - Updating weight to: [-0.44077999999999823, -0.20915999999999807]\n",
      "\n",
      "Error - Updating weight to: [-0.4416999999999982, -0.20875999999999806]\n",
      "\n",
      "Error - Updating weight to: [-0.4416999999999982, -0.20875999999999806]\n",
      "\n",
      "Error - Updating weight to: [-0.4416999999999982, -0.20875999999999806]\n",
      "\n",
      "Error - Updating weight to: [-0.4416999999999982, -0.20875999999999806]\n",
      "\n",
      "Error - Updating weight to: [-0.4416999999999982, -0.20875999999999806]\n",
      "\n",
      "Error - Updating weight to: [-0.4416999999999982, -0.20875999999999806]\n",
      "\n",
      "Error - Updating weight to: [-0.4426199999999982, -0.20835999999999805]\n",
      "\n",
      "Error - Updating weight to: [-0.4426199999999982, -0.20835999999999805]\n",
      "\n",
      "Error - Updating weight to: [-0.4426199999999982, -0.20835999999999805]\n",
      "\n",
      "Error - Updating weight to: [-0.4426199999999982, -0.20835999999999805]\n",
      "\n",
      "Error - Updating weight to: [-0.4426199999999982, -0.20835999999999805]\n",
      "\n",
      "Error - Updating weight to: [-0.4426199999999982, -0.20835999999999805]\n",
      "\n",
      "Error - Updating weight to: [-0.44353999999999816, -0.20795999999999804]\n",
      "\n",
      "Error - Updating weight to: [-0.44353999999999816, -0.20795999999999804]\n",
      "\n",
      "Error - Updating weight to: [-0.44353999999999816, -0.20795999999999804]\n",
      "\n",
      "Error - Updating weight to: [-0.44353999999999816, -0.20795999999999804]\n",
      "\n",
      "Error - Updating weight to: [-0.44353999999999816, -0.20795999999999804]\n",
      "\n",
      "Error - Updating weight to: [-0.44353999999999816, -0.20795999999999804]\n",
      "\n",
      "Error - Updating weight to: [-0.44445999999999813, -0.20755999999999802]\n",
      "\n",
      "Error - Updating weight to: [-0.44445999999999813, -0.20755999999999802]\n",
      "\n",
      "Error - Updating weight to: [-0.44445999999999813, -0.20755999999999802]\n",
      "\n",
      "Error - Updating weight to: [-0.44445999999999813, -0.20755999999999802]\n",
      "\n",
      "Error - Updating weight to: [-0.44445999999999813, -0.20755999999999802]\n",
      "\n",
      "Error - Updating weight to: [-0.44445999999999813, -0.20755999999999802]\n",
      "\n",
      "Error - Updating weight to: [-0.4453799999999981, -0.207159999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4453799999999981, -0.207159999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4453799999999981, -0.207159999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4453799999999981, -0.207159999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4453799999999981, -0.207159999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4453799999999981, -0.207159999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4462999999999981, -0.206759999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4462999999999981, -0.206759999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4462999999999981, -0.206759999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4462999999999981, -0.206759999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4462999999999981, -0.206759999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.4462999999999981, -0.206759999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.44721999999999806, -0.206359999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.44721999999999806, -0.206359999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.44721999999999806, -0.206359999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.44721999999999806, -0.206359999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.44721999999999806, -0.206359999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.44721999999999806, -0.206359999999998]\n",
      "\n",
      "Error - Updating weight to: [-0.44813999999999804, -0.20595999999999798]\n",
      "\n",
      "Error - Updating weight to: [-0.44813999999999804, -0.20595999999999798]\n",
      "\n",
      "Error - Updating weight to: [-0.44813999999999804, -0.20595999999999798]\n",
      "\n",
      "Error - Updating weight to: [-0.44813999999999804, -0.20595999999999798]\n",
      "\n",
      "Error - Updating weight to: [-0.44813999999999804, -0.20595999999999798]\n",
      "\n",
      "Error - Updating weight to: [-0.44813999999999804, -0.20595999999999798]\n",
      "\n",
      "Error - Updating weight to: [-0.449059999999998, -0.20555999999999797]\n",
      "\n",
      "Error - Updating weight to: [-0.449059999999998, -0.20555999999999797]\n",
      "\n",
      "Error - Updating weight to: [-0.449059999999998, -0.20555999999999797]\n",
      "\n",
      "Error - Updating weight to: [-0.449059999999998, -0.20555999999999797]\n",
      "\n",
      "Error - Updating weight to: [-0.449059999999998, -0.20555999999999797]\n",
      "\n",
      "Error - Updating weight to: [-0.449059999999998, -0.20555999999999797]\n",
      "\n",
      "Error - Updating weight to: [-0.449979999999998, -0.20515999999999796]\n",
      "\n",
      "Error - Updating weight to: [-0.449979999999998, -0.20515999999999796]\n",
      "\n",
      "Error - Updating weight to: [-0.449979999999998, -0.20515999999999796]\n",
      "\n",
      "Error - Updating weight to: [-0.449979999999998, -0.20515999999999796]\n",
      "\n",
      "Error - Updating weight to: [-0.449979999999998, -0.20515999999999796]\n",
      "\n",
      "Error - Updating weight to: [-0.449979999999998, -0.20515999999999796]\n",
      "\n",
      "Error - Updating weight to: [-0.45089999999999797, -0.20475999999999794]\n",
      "\n",
      "Error - Updating weight to: [-0.45089999999999797, -0.20475999999999794]\n",
      "\n",
      "Error - Updating weight to: [-0.45089999999999797, -0.20475999999999794]\n",
      "\n",
      "Error - Updating weight to: [-0.45089999999999797, -0.20475999999999794]\n",
      "\n",
      "Error - Updating weight to: [-0.45089999999999797, -0.20475999999999794]\n",
      "\n",
      "Error - Updating weight to: [-0.45089999999999797, -0.20475999999999794]\n",
      "\n",
      "Error - Updating weight to: [-0.45181999999999795, -0.20435999999999793]\n",
      "\n",
      "Error - Updating weight to: [-0.45181999999999795, -0.20435999999999793]\n",
      "\n",
      "Error - Updating weight to: [-0.45181999999999795, -0.20435999999999793]\n",
      "\n",
      "Error - Updating weight to: [-0.45181999999999795, -0.20435999999999793]\n",
      "\n",
      "Error - Updating weight to: [-0.45181999999999795, -0.20435999999999793]\n",
      "\n",
      "Error - Updating weight to: [-0.45181999999999795, -0.20435999999999793]\n",
      "\n",
      "Error - Updating weight to: [-0.4527399999999979, -0.20395999999999792]\n",
      "\n",
      "Error - Updating weight to: [-0.4527399999999979, -0.20395999999999792]\n",
      "\n",
      "Error - Updating weight to: [-0.4527399999999979, -0.20395999999999792]\n",
      "\n",
      "Error - Updating weight to: [-0.4527399999999979, -0.20395999999999792]\n",
      "\n",
      "Error - Updating weight to: [-0.4527399999999979, -0.20395999999999792]\n",
      "\n",
      "Error - Updating weight to: [-0.4527399999999979, -0.20395999999999792]\n",
      "\n",
      "Error - Updating weight to: [-0.4536599999999979, -0.2035599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4536599999999979, -0.2035599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4536599999999979, -0.2035599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4536599999999979, -0.2035599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4536599999999979, -0.2035599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4536599999999979, -0.2035599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4545799999999979, -0.2031599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4545799999999979, -0.2031599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4545799999999979, -0.2031599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4545799999999979, -0.2031599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4545799999999979, -0.2031599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4545799999999979, -0.2031599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.45549999999999785, -0.2027599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.45549999999999785, -0.2027599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.45549999999999785, -0.2027599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.45549999999999785, -0.2027599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.45549999999999785, -0.2027599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.45549999999999785, -0.2027599999999979]\n",
      "\n",
      "Error - Updating weight to: [-0.4564199999999978, -0.20235999999999787]\n",
      "\n",
      "Error - Updating weight to: [-0.4564199999999978, -0.20235999999999787]\n",
      "\n",
      "Error - Updating weight to: [-0.4564199999999978, -0.20235999999999787]\n",
      "\n",
      "Error - Updating weight to: [-0.4564199999999978, -0.20235999999999787]\n",
      "\n",
      "Error - Updating weight to: [-0.4564199999999978, -0.20235999999999787]\n",
      "\n",
      "Error - Updating weight to: [-0.4564199999999978, -0.20235999999999787]\n",
      "\n",
      "Error - Updating weight to: [-0.4573399999999978, -0.20195999999999786]\n",
      "\n",
      "Error - Updating weight to: [-0.4573399999999978, -0.20195999999999786]\n",
      "\n",
      "Error - Updating weight to: [-0.4573399999999978, -0.20195999999999786]\n",
      "\n",
      "Error - Updating weight to: [-0.4573399999999978, -0.20195999999999786]\n",
      "\n",
      "Error - Updating weight to: [-0.4573399999999978, -0.20195999999999786]\n",
      "\n",
      "Error - Updating weight to: [-0.4573399999999978, -0.20195999999999786]\n",
      "\n",
      "Error - Updating weight to: [-0.4582599999999978, -0.20155999999999785]\n",
      "\n",
      "Error - Updating weight to: [-0.4582599999999978, -0.20155999999999785]\n",
      "\n",
      "Error - Updating weight to: [-0.4582599999999978, -0.20155999999999785]\n",
      "\n",
      "Error - Updating weight to: [-0.4582599999999978, -0.20155999999999785]\n",
      "\n",
      "Error - Updating weight to: [-0.4582599999999978, -0.20155999999999785]\n",
      "\n",
      "Error - Updating weight to: [-0.4582599999999978, -0.20155999999999785]\n",
      "\n",
      "Error - Updating weight to: [-0.45917999999999776, -0.20115999999999784]\n",
      "\n",
      "Error - Updating weight to: [-0.45917999999999776, -0.20115999999999784]\n",
      "\n",
      "Error - Updating weight to: [-0.45917999999999776, -0.20115999999999784]\n",
      "\n",
      "Error - Updating weight to: [-0.45917999999999776, -0.20115999999999784]\n",
      "\n",
      "Error - Updating weight to: [-0.45917999999999776, -0.20115999999999784]\n",
      "\n",
      "Error - Updating weight to: [-0.45917999999999776, -0.20115999999999784]\n",
      "\n",
      "Error - Updating weight to: [-0.46009999999999773, -0.20075999999999783]\n",
      "\n",
      "Error - Updating weight to: [-0.46009999999999773, -0.20075999999999783]\n",
      "\n",
      "Error - Updating weight to: [-0.46009999999999773, -0.20075999999999783]\n",
      "\n",
      "Error - Updating weight to: [-0.46009999999999773, -0.20075999999999783]\n",
      "\n",
      "Error - Updating weight to: [-0.46009999999999773, -0.20075999999999783]\n",
      "\n",
      "Error - Updating weight to: [-0.46009999999999773, -0.20075999999999783]\n",
      "\n",
      "Error - Updating weight to: [-0.4610199999999977, -0.20035999999999782]\n",
      "\n",
      "Error - Updating weight to: [-0.4610199999999977, -0.20035999999999782]\n",
      "\n",
      "Error - Updating weight to: [-0.4610199999999977, -0.20035999999999782]\n",
      "\n",
      "Error - Updating weight to: [-0.4610199999999977, -0.20035999999999782]\n",
      "\n",
      "Error - Updating weight to: [-0.4610199999999977, -0.20035999999999782]\n",
      "\n",
      "Error - Updating weight to: [-0.4610199999999977, -0.20035999999999782]\n",
      "\n",
      "Error - Updating weight to: [-0.4619399999999977, -0.1999599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.4619399999999977, -0.1999599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.4619399999999977, -0.1999599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.4619399999999977, -0.1999599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.4619399999999977, -0.1999599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.4619399999999977, -0.1999599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.46285999999999766, -0.1995599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.46285999999999766, -0.1995599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.46285999999999766, -0.1995599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.46285999999999766, -0.1995599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.46285999999999766, -0.1995599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.46285999999999766, -0.1995599999999978]\n",
      "\n",
      "Error - Updating weight to: [-0.46377999999999764, -0.19915999999999778]\n",
      "\n",
      "Error - Updating weight to: [-0.46377999999999764, -0.19915999999999778]\n",
      "\n",
      "Error - Updating weight to: [-0.46377999999999764, -0.19915999999999778]\n",
      "\n",
      "Error - Updating weight to: [-0.46377999999999764, -0.19915999999999778]\n",
      "\n",
      "Error - Updating weight to: [-0.46377999999999764, -0.19915999999999778]\n",
      "\n",
      "Error - Updating weight to: [-0.46377999999999764, -0.19915999999999778]\n",
      "\n",
      "Error - Updating weight to: [-0.4646999999999976, -0.19875999999999777]\n",
      "\n",
      "Error - Updating weight to: [-0.4646999999999976, -0.19875999999999777]\n",
      "\n",
      "Error - Updating weight to: [-0.4646999999999976, -0.19875999999999777]\n",
      "\n",
      "Error - Updating weight to: [-0.4646999999999976, -0.19875999999999777]\n",
      "\n",
      "Error - Updating weight to: [-0.4646999999999976, -0.19875999999999777]\n",
      "\n",
      "Error - Updating weight to: [-0.4646999999999976, -0.19875999999999777]\n",
      "\n",
      "Error - Updating weight to: [-0.4656199999999976, -0.19835999999999776]\n",
      "\n",
      "Error - Updating weight to: [-0.4656199999999976, -0.19835999999999776]\n",
      "\n",
      "Error - Updating weight to: [-0.4656199999999976, -0.19835999999999776]\n",
      "\n",
      "Error - Updating weight to: [-0.4656199999999976, -0.19835999999999776]\n",
      "\n",
      "Error - Updating weight to: [-0.4656199999999976, -0.19835999999999776]\n",
      "\n",
      "Error - Updating weight to: [-0.4656199999999976, -0.19835999999999776]\n",
      "\n",
      "Error - Updating weight to: [-0.46653999999999757, -0.19795999999999775]\n",
      "\n",
      "Error - Updating weight to: [-0.46653999999999757, -0.19795999999999775]\n",
      "\n",
      "Error - Updating weight to: [-0.46653999999999757, -0.19795999999999775]\n",
      "\n",
      "Error - Updating weight to: [-0.46653999999999757, -0.19795999999999775]\n",
      "\n",
      "Error - Updating weight to: [-0.46653999999999757, -0.19795999999999775]\n",
      "\n",
      "Error - Updating weight to: [-0.46653999999999757, -0.19795999999999775]\n",
      "\n",
      "Error - Updating weight to: [-0.46745999999999754, -0.19755999999999774]\n",
      "\n",
      "Error - Updating weight to: [-0.46745999999999754, -0.19755999999999774]\n",
      "\n",
      "Error - Updating weight to: [-0.46745999999999754, -0.19755999999999774]\n",
      "\n",
      "Error - Updating weight to: [-0.46745999999999754, -0.19755999999999774]\n",
      "\n",
      "Error - Updating weight to: [-0.46745999999999754, -0.19755999999999774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error - Updating weight to: [-0.46745999999999754, -0.19755999999999774]\n",
      "\n",
      "Error - Updating weight to: [-0.4683799999999975, -0.19715999999999773]\n",
      "\n",
      "Error - Updating weight to: [-0.4683799999999975, -0.19715999999999773]\n",
      "\n",
      "Error - Updating weight to: [-0.4683799999999975, -0.19715999999999773]\n",
      "\n",
      "Error - Updating weight to: [-0.4683799999999975, -0.19715999999999773]\n",
      "\n",
      "Error - Updating weight to: [-0.4683799999999975, -0.19715999999999773]\n",
      "\n",
      "Error - Updating weight to: [-0.4683799999999975, -0.19715999999999773]\n",
      "\n",
      "Error - Updating weight to: [-0.4692999999999975, -0.19675999999999771]\n",
      "\n",
      "Error - Updating weight to: [-0.4692999999999975, -0.19675999999999771]\n",
      "\n",
      "Error - Updating weight to: [-0.4692999999999975, -0.19675999999999771]\n",
      "\n",
      "Error - Updating weight to: [-0.4692999999999975, -0.19675999999999771]\n",
      "\n",
      "Error - Updating weight to: [-0.4692999999999975, -0.19675999999999771]\n",
      "\n",
      "Error - Updating weight to: [-0.4692999999999975, -0.19675999999999771]\n",
      "\n",
      "Error - Updating weight to: [-0.4702199999999975, -0.1963599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.4702199999999975, -0.1963599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.4702199999999975, -0.1963599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.4702199999999975, -0.1963599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.4702199999999975, -0.1963599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.4702199999999975, -0.1963599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.47113999999999745, -0.1959599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.47113999999999745, -0.1959599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.47113999999999745, -0.1959599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.47113999999999745, -0.1959599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.47113999999999745, -0.1959599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.47113999999999745, -0.1959599999999977]\n",
      "\n",
      "Error - Updating weight to: [-0.4720599999999974, -0.19555999999999768]\n",
      "\n",
      "Error - Updating weight to: [-0.4720599999999974, -0.19555999999999768]\n",
      "\n",
      "Error - Updating weight to: [-0.4720599999999974, -0.19555999999999768]\n",
      "\n",
      "Error - Updating weight to: [-0.4720599999999974, -0.19555999999999768]\n",
      "\n",
      "Error - Updating weight to: [-0.4720599999999974, -0.19555999999999768]\n",
      "\n",
      "Error - Updating weight to: [-0.4720599999999974, -0.19555999999999768]\n",
      "\n",
      "Error - Updating weight to: [-0.4729799999999974, -0.19515999999999767]\n",
      "\n",
      "Error - Updating weight to: [-0.4729799999999974, -0.19515999999999767]\n",
      "\n",
      "Error - Updating weight to: [-0.4729799999999974, -0.19515999999999767]\n",
      "\n",
      "Error - Updating weight to: [-0.4729799999999974, -0.19515999999999767]\n",
      "\n",
      "Error - Updating weight to: [-0.4729799999999974, -0.19515999999999767]\n",
      "\n",
      "Error - Updating weight to: [-0.4729799999999974, -0.19515999999999767]\n",
      "\n",
      "Error - Updating weight to: [-0.4738999999999974, -0.19475999999999766]\n",
      "\n",
      "Error - Updating weight to: [-0.4738999999999974, -0.19475999999999766]\n",
      "\n",
      "Error - Updating weight to: [-0.4738999999999974, -0.19475999999999766]\n",
      "\n",
      "Error - Updating weight to: [-0.4738999999999974, -0.19475999999999766]\n",
      "\n",
      "Error - Updating weight to: [-0.4738999999999974, -0.19475999999999766]\n",
      "\n",
      "Error - Updating weight to: [-0.4738999999999974, -0.19475999999999766]\n",
      "\n",
      "Error - Updating weight to: [-0.47481999999999736, -0.19435999999999765]\n",
      "\n",
      "Error - Updating weight to: [-0.47481999999999736, -0.19435999999999765]\n",
      "\n",
      "Error - Updating weight to: [-0.47481999999999736, -0.19435999999999765]\n",
      "\n",
      "Error - Updating weight to: [-0.47481999999999736, -0.19435999999999765]\n",
      "\n",
      "Error - Updating weight to: [-0.47481999999999736, -0.19435999999999765]\n",
      "\n",
      "Error - Updating weight to: [-0.47481999999999736, -0.19435999999999765]\n",
      "\n",
      "Error - Updating weight to: [-0.47573999999999733, -0.19395999999999763]\n",
      "\n",
      "Error - Updating weight to: [-0.47573999999999733, -0.19395999999999763]\n",
      "\n",
      "Error - Updating weight to: [-0.47573999999999733, -0.19395999999999763]\n",
      "\n",
      "Error - Updating weight to: [-0.47573999999999733, -0.19395999999999763]\n",
      "\n",
      "Error - Updating weight to: [-0.47573999999999733, -0.19395999999999763]\n",
      "\n",
      "Error - Updating weight to: [-0.47573999999999733, -0.19395999999999763]\n",
      "\n",
      "Error - Updating weight to: [-0.4766599999999973, -0.19355999999999762]\n",
      "\n",
      "Error - Updating weight to: [-0.4766599999999973, -0.19355999999999762]\n",
      "\n",
      "Error - Updating weight to: [-0.4766599999999973, -0.19355999999999762]\n",
      "\n",
      "Error - Updating weight to: [-0.4766599999999973, -0.19355999999999762]\n",
      "\n",
      "Error - Updating weight to: [-0.4766599999999973, -0.19355999999999762]\n",
      "\n",
      "Error - Updating weight to: [-0.4766599999999973, -0.19355999999999762]\n",
      "\n",
      "Error - Updating weight to: [-0.4775799999999973, -0.1931599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.4775799999999973, -0.1931599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.4775799999999973, -0.1931599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.4775799999999973, -0.1931599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.4775799999999973, -0.1931599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.4775799999999973, -0.1931599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47849999999999726, -0.1927599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47849999999999726, -0.1927599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47849999999999726, -0.1927599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47849999999999726, -0.1927599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47849999999999726, -0.1927599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47849999999999726, -0.1927599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47941999999999724, -0.1923599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47941999999999724, -0.1923599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47941999999999724, -0.1923599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47941999999999724, -0.1923599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47941999999999724, -0.1923599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.47941999999999724, -0.1923599999999976]\n",
      "\n",
      "Error - Updating weight to: [-0.4803399999999972, -0.19195999999999758]\n",
      "\n",
      "Error - Updating weight to: [-0.4803399999999972, -0.19195999999999758]\n",
      "\n",
      "Error - Updating weight to: [-0.4803399999999972, -0.19195999999999758]\n",
      "\n",
      "Error - Updating weight to: [-0.4803399999999972, -0.19195999999999758]\n",
      "\n",
      "Error - Updating weight to: [-0.4803399999999972, -0.19195999999999758]\n",
      "\n",
      "Error - Updating weight to: [-0.4803399999999972, -0.19195999999999758]\n",
      "\n",
      "Error - Updating weight to: [-0.4812599999999972, -0.19155999999999757]\n",
      "\n",
      "Error - Updating weight to: [-0.4812599999999972, -0.19155999999999757]\n",
      "\n",
      "Error - Updating weight to: [-0.4812599999999972, -0.19155999999999757]\n",
      "\n",
      "Error - Updating weight to: [-0.4812599999999972, -0.19155999999999757]\n",
      "\n",
      "Error - Updating weight to: [-0.4812599999999972, -0.19155999999999757]\n",
      "\n",
      "Error - Updating weight to: [-0.4812599999999972, -0.19155999999999757]\n",
      "\n",
      "Error - Updating weight to: [-0.48217999999999717, -0.19115999999999755]\n",
      "\n",
      "Error - Updating weight to: [-0.48217999999999717, -0.19115999999999755]\n",
      "\n",
      "Error - Updating weight to: [-0.48217999999999717, -0.19115999999999755]\n",
      "\n",
      "Error - Updating weight to: [-0.48217999999999717, -0.19115999999999755]\n",
      "\n",
      "Error - Updating weight to: [-0.48217999999999717, -0.19115999999999755]\n",
      "\n",
      "Error - Updating weight to: [-0.48217999999999717, -0.19115999999999755]\n",
      "\n",
      "Error - Updating weight to: [-0.48309999999999714, -0.19075999999999754]\n",
      "\n",
      "Error - Updating weight to: [-0.48309999999999714, -0.19075999999999754]\n",
      "\n",
      "Error - Updating weight to: [-0.48309999999999714, -0.19075999999999754]\n",
      "\n",
      "Error - Updating weight to: [-0.48309999999999714, -0.19075999999999754]\n",
      "\n",
      "Error - Updating weight to: [-0.48309999999999714, -0.19075999999999754]\n",
      "\n",
      "Error - Updating weight to: [-0.48309999999999714, -0.19075999999999754]\n",
      "\n",
      "Error - Updating weight to: [-0.4840199999999971, -0.19035999999999753]\n",
      "\n",
      "Error - Updating weight to: [-0.4840199999999971, -0.19035999999999753]\n",
      "\n",
      "Error - Updating weight to: [-0.4840199999999971, -0.19035999999999753]\n",
      "\n",
      "Error - Updating weight to: [-0.4840199999999971, -0.19035999999999753]\n",
      "\n",
      "Error - Updating weight to: [-0.4840199999999971, -0.19035999999999753]\n",
      "\n",
      "Error - Updating weight to: [-0.4840199999999971, -0.19035999999999753]\n",
      "\n",
      "Error - Updating weight to: [-0.4849399999999971, -0.18995999999999752]\n",
      "\n",
      "Error - Updating weight to: [-0.4849399999999971, -0.18995999999999752]\n",
      "\n",
      "Error - Updating weight to: [-0.4849399999999971, -0.18995999999999752]\n",
      "\n",
      "Error - Updating weight to: [-0.4849399999999971, -0.18995999999999752]\n",
      "\n",
      "Error - Updating weight to: [-0.4849399999999971, -0.18995999999999752]\n",
      "\n",
      "Error - Updating weight to: [-0.4849399999999971, -0.18995999999999752]\n",
      "\n",
      "Error - Updating weight to: [-0.48585999999999707, -0.1895599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48585999999999707, -0.1895599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48585999999999707, -0.1895599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48585999999999707, -0.1895599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48585999999999707, -0.1895599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48585999999999707, -0.1895599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48677999999999705, -0.1891599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48677999999999705, -0.1891599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48677999999999705, -0.1891599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48677999999999705, -0.1891599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48677999999999705, -0.1891599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.48677999999999705, -0.1891599999999975]\n",
      "\n",
      "Error - Updating weight to: [-0.487699999999997, -0.18875999999999749]\n",
      "\n",
      "Error - Updating weight to: [-0.487699999999997, -0.18875999999999749]\n",
      "\n",
      "Error - Updating weight to: [-0.487699999999997, -0.18875999999999749]\n",
      "\n",
      "Error - Updating weight to: [-0.487699999999997, -0.18875999999999749]\n",
      "\n",
      "Error - Updating weight to: [-0.487699999999997, -0.18875999999999749]\n",
      "\n",
      "Error - Updating weight to: [-0.487699999999997, -0.18875999999999749]\n",
      "\n",
      "Error - Updating weight to: [-0.488619999999997, -0.18835999999999747]\n",
      "\n",
      "Error - Updating weight to: [-0.488619999999997, -0.18835999999999747]\n",
      "\n",
      "Error - Updating weight to: [-0.488619999999997, -0.18835999999999747]\n",
      "\n",
      "Error - Updating weight to: [-0.488619999999997, -0.18835999999999747]\n",
      "\n",
      "Error - Updating weight to: [-0.488619999999997, -0.18835999999999747]\n",
      "\n",
      "Error - Updating weight to: [-0.488619999999997, -0.18835999999999747]\n",
      "\n",
      "Error - Updating weight to: [-0.489539999999997, -0.18795999999999746]\n",
      "\n",
      "Error - Updating weight to: [-0.489539999999997, -0.18795999999999746]\n",
      "\n",
      "Error - Updating weight to: [-0.489539999999997, -0.18795999999999746]\n",
      "\n",
      "Error - Updating weight to: [-0.489539999999997, -0.18795999999999746]\n",
      "\n",
      "Error - Updating weight to: [-0.489539999999997, -0.18795999999999746]\n",
      "\n",
      "Error - Updating weight to: [-0.489539999999997, -0.18795999999999746]\n",
      "\n",
      "Error - Updating weight to: [-0.49045999999999695, -0.18755999999999745]\n",
      "\n",
      "Error - Updating weight to: [-0.49045999999999695, -0.18755999999999745]\n",
      "\n",
      "Error - Updating weight to: [-0.49045999999999695, -0.18755999999999745]\n",
      "\n",
      "Error - Updating weight to: [-0.49045999999999695, -0.18755999999999745]\n",
      "\n",
      "Error - Updating weight to: [-0.49045999999999695, -0.18755999999999745]\n",
      "\n",
      "Error - Updating weight to: [-0.49045999999999695, -0.18755999999999745]\n",
      "\n",
      "Error - Updating weight to: [-0.49137999999999693, -0.18715999999999744]\n",
      "\n",
      "Error - Updating weight to: [-0.49137999999999693, -0.18715999999999744]\n",
      "\n",
      "Error - Updating weight to: [-0.49137999999999693, -0.18715999999999744]\n",
      "\n",
      "Error - Updating weight to: [-0.49137999999999693, -0.18715999999999744]\n",
      "\n",
      "Error - Updating weight to: [-0.49137999999999693, -0.18715999999999744]\n",
      "\n",
      "Error - Updating weight to: [-0.49137999999999693, -0.18715999999999744]\n",
      "\n",
      "Error - Updating weight to: [-0.4922999999999969, -0.18675999999999743]\n",
      "\n",
      "Error - Updating weight to: [-0.4922999999999969, -0.18675999999999743]\n",
      "\n",
      "Error - Updating weight to: [-0.4922999999999969, -0.18675999999999743]\n",
      "\n",
      "Error - Updating weight to: [-0.4922999999999969, -0.18675999999999743]\n",
      "\n",
      "Error - Updating weight to: [-0.4922999999999969, -0.18675999999999743]\n",
      "\n",
      "Error - Updating weight to: [-0.4922999999999969, -0.18675999999999743]\n",
      "\n",
      "Error - Updating weight to: [-0.4932199999999969, -0.18635999999999742]\n",
      "\n",
      "Error - Updating weight to: [-0.4932199999999969, -0.18635999999999742]\n",
      "\n",
      "Error - Updating weight to: [-0.4932199999999969, -0.18635999999999742]\n",
      "\n",
      "Error - Updating weight to: [-0.4932199999999969, -0.18635999999999742]\n",
      "\n",
      "Error - Updating weight to: [-0.4932199999999969, -0.18635999999999742]\n",
      "\n",
      "Error - Updating weight to: [-0.4932199999999969, -0.18635999999999742]\n",
      "\n",
      "Error - Updating weight to: [-0.49413999999999686, -0.1859599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49413999999999686, -0.1859599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49413999999999686, -0.1859599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49413999999999686, -0.1859599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49413999999999686, -0.1859599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49413999999999686, -0.1859599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49505999999999684, -0.1855599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49505999999999684, -0.1855599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49505999999999684, -0.1855599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49505999999999684, -0.1855599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49505999999999684, -0.1855599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.49505999999999684, -0.1855599999999974]\n",
      "\n",
      "Error - Updating weight to: [-0.4959799999999968, -0.18515999999999738]\n",
      "\n",
      "Error - Updating weight to: [-0.4959799999999968, -0.18515999999999738]\n",
      "\n",
      "Error - Updating weight to: [-0.4959799999999968, -0.18515999999999738]\n",
      "\n",
      "Error - Updating weight to: [-0.4959799999999968, -0.18515999999999738]\n",
      "\n",
      "Error - Updating weight to: [-0.4959799999999968, -0.18515999999999738]\n",
      "\n",
      "Error - Updating weight to: [-0.4959799999999968, -0.18515999999999738]\n",
      "\n",
      "Error - Updating weight to: [-0.4968999999999968, -0.18475999999999737]\n",
      "\n",
      "Error - Updating weight to: [-0.4968999999999968, -0.18475999999999737]\n",
      "\n",
      "Error - Updating weight to: [-0.4968999999999968, -0.18475999999999737]\n",
      "\n",
      "Error - Updating weight to: [-0.4968999999999968, -0.18475999999999737]\n",
      "\n",
      "Error - Updating weight to: [-0.4968999999999968, -0.18475999999999737]\n",
      "\n",
      "Error - Updating weight to: [-0.4968999999999968, -0.18475999999999737]\n",
      "\n",
      "Error - Updating weight to: [-0.49781999999999677, -0.18435999999999736]\n",
      "\n",
      "Error - Updating weight to: [-0.49781999999999677, -0.18435999999999736]\n",
      "\n",
      "Error - Updating weight to: [-0.49781999999999677, -0.18435999999999736]\n",
      "\n",
      "Error - Updating weight to: [-0.49781999999999677, -0.18435999999999736]\n",
      "\n",
      "Error - Updating weight to: [-0.49781999999999677, -0.18435999999999736]\n",
      "\n",
      "Error - Updating weight to: [-0.49781999999999677, -0.18435999999999736]\n",
      "\n",
      "Error - Updating weight to: [-0.49873999999999674, -0.18395999999999735]\n",
      "\n",
      "Error - Updating weight to: [-0.49873999999999674, -0.18395999999999735]\n",
      "\n",
      "Error - Updating weight to: [-0.49873999999999674, -0.18395999999999735]\n",
      "\n",
      "Error - Updating weight to: [-0.49873999999999674, -0.18395999999999735]\n",
      "\n",
      "Error - Updating weight to: [-0.49873999999999674, -0.18395999999999735]\n",
      "\n",
      "Error - Updating weight to: [-0.49873999999999674, -0.18395999999999735]\n",
      "\n",
      "Error - Updating weight to: [-0.4996599999999967, -0.18355999999999734]\n",
      "\n",
      "Error - Updating weight to: [-0.4996599999999967, -0.18355999999999734]\n",
      "\n",
      "Error - Updating weight to: [-0.4996599999999967, -0.18355999999999734]\n",
      "\n",
      "Error - Updating weight to: [-0.4996599999999967, -0.18355999999999734]\n",
      "\n",
      "Error - Updating weight to: [-0.4996599999999967, -0.18355999999999734]\n",
      "\n",
      "Error - Updating weight to: [-0.4996599999999967, -0.18355999999999734]\n",
      "\n",
      "Error - Updating weight to: [-0.5005799999999967, -0.18315999999999732]\n",
      "\n",
      "Error - Updating weight to: [-0.5005799999999967, -0.18315999999999732]\n",
      "\n",
      "Error - Updating weight to: [-0.5005799999999967, -0.18315999999999732]\n",
      "\n",
      "Error - Updating weight to: [-0.5005799999999967, -0.18315999999999732]\n",
      "\n",
      "Error - Updating weight to: [-0.5005799999999967, -0.18315999999999732]\n",
      "\n",
      "Error - Updating weight to: [-0.5005799999999967, -0.18315999999999732]\n",
      "\n",
      "Error - Updating weight to: [-0.5014999999999967, -0.1827599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5014999999999967, -0.1827599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5014999999999967, -0.1827599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5014999999999967, -0.1827599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5014999999999967, -0.1827599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5014999999999967, -0.1827599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5024199999999968, -0.1823599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5024199999999968, -0.1823599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5024199999999968, -0.1823599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5024199999999968, -0.1823599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5024199999999968, -0.1823599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5024199999999968, -0.1823599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "Error - Updating weight to: [-0.5033399999999968, -0.1819599999999973]\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "functionality learned with 268 iterations!\n"
     ]
    }
   ],
   "source": [
    "w = [0,0]  # weights\n",
    "\n",
    "threshold = 0\n",
    "\n",
    "bias = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "max_iterations = 1000\n",
    "\n",
    "x = [\n",
    "    [0.72,0.82,-1],\n",
    "    [0.92,-0.4,-1],\n",
    "    [0.78,0.86,-1],\n",
    "    [0.34,0.11,1],\n",
    "    [0.12,-0.23,1],\n",
    "    [-0.1,-0.9,1]\n",
    "]\n",
    "\n",
    "\n",
    "y = 0 # output\n",
    "\n",
    "answer = \"\"  # correct or error\n",
    "\n",
    "for k in range(1,max_iterations):\n",
    "    hits = 0\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        sum = 0\n",
    "        \n",
    "        # weigthed sum\n",
    "        for j in range(0,len(x[i])-1):\n",
    "            sum += x[i][j]*w[j]\n",
    "            \n",
    "        output  = sum + bias\n",
    "        \n",
    "        if output > threshold:\n",
    "            y = 1\n",
    "        else:\n",
    "            y = -1\n",
    "            \n",
    "        # update weights if the output does not match\n",
    "        if y == x[i][2]:\n",
    "            hits += 1\n",
    "        else:\n",
    "            for j in range(0,len(w)):\n",
    "                w[j] += learning_rate*x[i][2]*x[i][j]\n",
    "            bias += learning_rate*x[i][2]\n",
    "                \n",
    "        answer = \"Error - Updating weight to: \"+ str(w)\n",
    "        \n",
    "        \n",
    "        # print answer\n",
    "        if y == 1:\n",
    "            print(\"\\n\"+answer)\n",
    "        elif y == -1:\n",
    "            print(\"\\n\"+answer)\n",
    "            \n",
    "    if hits == len(x):\n",
    "        print(\"\\n--------------------------------------------------------------------\")\n",
    "        print(\"functionality learned with \"+str(k)+\" iterations!\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c15da40",
   "metadata": {},
   "source": [
    "# Single Layer Perceptron For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "001b3c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 0.2573 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2573 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2572 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2572 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2571 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2571 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2571 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2571 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2569 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2569 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2569 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2569 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2568 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2567 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2567 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2567 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2566 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2565 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2565 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2563 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2563 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2563 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2561 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2561 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2560 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2560 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2560 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2560 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2559 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2559 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2558 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2558 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2557 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2557 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2557 - accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2557 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2556 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2556 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2556 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2556 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2556 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2555 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2555 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2555 - accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2555 - accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2555 - accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2554 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2554 - accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2554 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2554 - accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2554 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2554 - accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2553 - accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2553 - accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2553 - accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2553 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2552 - accuracy: 0.5000\n",
      "Accuracy: 50.00\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(2,input_shape=(2,),activation='sigmoid'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x,y,epochs=100,batch_size=10)\n",
    "\n",
    "_,accuracy = model.evaluate(x,y)\n",
    "\n",
    "print('Accuracy: %.2f'%(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eb10b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fe7873b",
   "metadata": {},
   "source": [
    "# Linear Regression using Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0bd9f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.7578 - accuracy: 0.2708 - val_loss: 0.5542 - val_accuracy: 0.4583\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6701 - accuracy: 0.2708 - val_loss: 0.5270 - val_accuracy: 0.4583\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6050 - accuracy: 0.2708 - val_loss: 0.4769 - val_accuracy: 0.4583\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5359 - accuracy: 0.2708 - val_loss: 0.4331 - val_accuracy: 0.4583\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4886 - accuracy: 0.2708 - val_loss: 0.3875 - val_accuracy: 0.4583\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4447 - accuracy: 0.2708 - val_loss: 0.3507 - val_accuracy: 0.4583\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4013 - accuracy: 0.2708 - val_loss: 0.3193 - val_accuracy: 0.4583\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3587 - accuracy: 0.2708 - val_loss: 0.2914 - val_accuracy: 0.4583\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3184 - accuracy: 0.2708 - val_loss: 0.2711 - val_accuracy: 0.4583\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2853 - accuracy: 0.2708 - val_loss: 0.2513 - val_accuracy: 0.4583\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2551 - accuracy: 0.2708 - val_loss: 0.2177 - val_accuracy: 0.4583\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2215 - accuracy: 0.2812 - val_loss: 0.1914 - val_accuracy: 0.4583\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1976 - accuracy: 0.3750 - val_loss: 0.1686 - val_accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1707 - accuracy: 0.5208 - val_loss: 0.1528 - val_accuracy: 0.7083\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1458 - accuracy: 0.5625 - val_loss: 0.1382 - val_accuracy: 0.7500\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1257 - accuracy: 0.5833 - val_loss: 0.1265 - val_accuracy: 0.7500\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1089 - accuracy: 0.6042 - val_loss: 0.1136 - val_accuracy: 0.7500\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0965 - accuracy: 0.6042 - val_loss: 0.1053 - val_accuracy: 0.7500\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0867 - accuracy: 0.6042 - val_loss: 0.0964 - val_accuracy: 0.7500\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0761 - accuracy: 0.6042 - val_loss: 0.0912 - val_accuracy: 0.7500\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0693 - accuracy: 0.6042 - val_loss: 0.0871 - val_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0647 - accuracy: 0.6042 - val_loss: 0.0794 - val_accuracy: 0.7500\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0584 - accuracy: 0.6042 - val_loss: 0.0760 - val_accuracy: 0.7500\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0549 - accuracy: 0.6042 - val_loss: 0.0751 - val_accuracy: 0.7500\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0516 - accuracy: 0.6042 - val_loss: 0.0735 - val_accuracy: 0.7500\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0494 - accuracy: 0.6042 - val_loss: 0.0718 - val_accuracy: 0.7500\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0482 - accuracy: 0.6042 - val_loss: 0.0709 - val_accuracy: 0.7500\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0469 - accuracy: 0.6042 - val_loss: 0.0701 - val_accuracy: 0.7500\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0474 - accuracy: 0.6042 - val_loss: 0.0705 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0457 - accuracy: 0.6042 - val_loss: 0.0686 - val_accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0456 - accuracy: 0.6042 - val_loss: 0.0684 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0457 - accuracy: 0.6042 - val_loss: 0.0674 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0456 - accuracy: 0.6042 - val_loss: 0.0684 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0439 - accuracy: 0.6042 - val_loss: 0.0671 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0439 - accuracy: 0.6042 - val_loss: 0.0661 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0441 - accuracy: 0.6042 - val_loss: 0.0663 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0428 - accuracy: 0.6042 - val_loss: 0.0656 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0425 - accuracy: 0.6042 - val_loss: 0.0651 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0425 - accuracy: 0.6042 - val_loss: 0.0650 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0418 - accuracy: 0.6042 - val_loss: 0.0655 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0424 - accuracy: 0.6042 - val_loss: 0.0652 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0416 - accuracy: 0.6042 - val_loss: 0.0643 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0419 - accuracy: 0.6042 - val_loss: 0.0644 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0452 - accuracy: 0.6042 - val_loss: 0.0654 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0411 - accuracy: 0.6042 - val_loss: 0.0637 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0401 - accuracy: 0.6042 - val_loss: 0.0636 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0406 - accuracy: 0.6042 - val_loss: 0.0633 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0402 - accuracy: 0.6042 - val_loss: 0.0634 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0399 - accuracy: 0.6042 - val_loss: 0.0630 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0395 - accuracy: 0.6042 - val_loss: 0.0627 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0393 - accuracy: 0.6042 - val_loss: 0.0626 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0398 - accuracy: 0.6042 - val_loss: 0.0624 - val_accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0389 - accuracy: 0.6042 - val_loss: 0.0624 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0395 - accuracy: 0.6042 - val_loss: 0.0620 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0390 - accuracy: 0.6042 - val_loss: 0.0620 - val_accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.6042 - val_loss: 0.0620 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0386 - accuracy: 0.6042 - val_loss: 0.0618 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0385 - accuracy: 0.6042 - val_loss: 0.0619 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0392 - accuracy: 0.6042 - val_loss: 0.0619 - val_accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0379 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0387 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0388 - accuracy: 0.6042 - val_loss: 0.0626 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0397 - accuracy: 0.6042 - val_loss: 0.0626 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0379 - accuracy: 0.6042 - val_loss: 0.0623 - val_accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0389 - accuracy: 0.6042 - val_loss: 0.0619 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0370 - accuracy: 0.6042 - val_loss: 0.0627 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0391 - accuracy: 0.6042 - val_loss: 0.0637 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0377 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0387 - accuracy: 0.6042 - val_loss: 0.0617 - val_accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0373 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 0.6042 - val_loss: 0.0629 - val_accuracy: 0.7500\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0389 - accuracy: 0.6042 - val_loss: 0.0612 - val_accuracy: 0.7500\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 0.6042 - val_loss: 0.0613 - val_accuracy: 0.7500\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0367 - accuracy: 0.6042 - val_loss: 0.0618 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0368 - accuracy: 0.6042 - val_loss: 0.0614 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0370 - accuracy: 0.6042 - val_loss: 0.0610 - val_accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0365 - accuracy: 0.6042 - val_loss: 0.0609 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0362 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0362 - accuracy: 0.6042 - val_loss: 0.0612 - val_accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0361 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0361 - accuracy: 0.6042 - val_loss: 0.0608 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0361 - accuracy: 0.6042 - val_loss: 0.0609 - val_accuracy: 0.7500\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0365 - accuracy: 0.6042 - val_loss: 0.0610 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0358 - accuracy: 0.6042 - val_loss: 0.0607 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0359 - accuracy: 0.6042 - val_loss: 0.0608 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0358 - accuracy: 0.6042 - val_loss: 0.0609 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0356 - accuracy: 0.6042 - val_loss: 0.0610 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0358 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0355 - accuracy: 0.6042 - val_loss: 0.0609 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0354 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0368 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0352 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0354 - accuracy: 0.6042 - val_loss: 0.0620 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0353 - accuracy: 0.6042 - val_loss: 0.0608 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0356 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0353 - accuracy: 0.6042 - val_loss: 0.0621 - val_accuracy: 0.7500\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0372 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0373 - accuracy: 0.6042 - val_loss: 0.0629 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0366 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0350 - accuracy: 0.6042 - val_loss: 0.0607 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0349 - accuracy: 0.6042 - val_loss: 0.0622 - val_accuracy: 0.7500\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0350 - accuracy: 0.6042 - val_loss: 0.0614 - val_accuracy: 0.7500\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0384 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0357 - accuracy: 0.6042 - val_loss: 0.0631 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0358 - accuracy: 0.6042 - val_loss: 0.0625 - val_accuracy: 0.7500\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0376 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0350 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0342 - accuracy: 0.6042 - val_loss: 0.0628 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0347 - accuracy: 0.6042 - val_loss: 0.0612 - val_accuracy: 0.7500\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0342 - accuracy: 0.6042 - val_loss: 0.0605 - val_accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0352 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0343 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0342 - accuracy: 0.6042 - val_loss: 0.0610 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0344 - accuracy: 0.6042 - val_loss: 0.0621 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0342 - accuracy: 0.6042 - val_loss: 0.0605 - val_accuracy: 0.7500\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0342 - accuracy: 0.6042 - val_loss: 0.0605 - val_accuracy: 0.7500\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0357 - accuracy: 0.6042 - val_loss: 0.0622 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0340 - accuracy: 0.6042 - val_loss: 0.0604 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0342 - accuracy: 0.6042 - val_loss: 0.0608 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0338 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0344 - accuracy: 0.6042 - val_loss: 0.0627 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0340 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0344 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0334 - accuracy: 0.6042 - val_loss: 0.0627 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0353 - accuracy: 0.6042 - val_loss: 0.0633 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0333 - accuracy: 0.6042 - val_loss: 0.0606 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0340 - accuracy: 0.6042 - val_loss: 0.0607 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0340 - accuracy: 0.6042 - val_loss: 0.0626 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0336 - accuracy: 0.6042 - val_loss: 0.0619 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0341 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0345 - accuracy: 0.6042 - val_loss: 0.0609 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0337 - accuracy: 0.6042 - val_loss: 0.0632 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0336 - accuracy: 0.6042 - val_loss: 0.0627 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0335 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0333 - accuracy: 0.6042 - val_loss: 0.0612 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0337 - accuracy: 0.6042 - val_loss: 0.0631 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0335 - accuracy: 0.6042 - val_loss: 0.0623 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0332 - accuracy: 0.6042 - val_loss: 0.0620 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0330 - accuracy: 0.6042 - val_loss: 0.0617 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0330 - accuracy: 0.6042 - val_loss: 0.0617 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0329 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0336 - accuracy: 0.6042 - val_loss: 0.0625 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0330 - accuracy: 0.6042 - val_loss: 0.0626 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0337 - accuracy: 0.6042 - val_loss: 0.0611 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0329 - accuracy: 0.6042 - val_loss: 0.0620 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0327 - accuracy: 0.6042 - val_loss: 0.0643 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0336 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0325 - accuracy: 0.6042 - val_loss: 0.0614 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0328 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0324 - accuracy: 0.6042 - val_loss: 0.0636 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0333 - accuracy: 0.6042 - val_loss: 0.0619 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0323 - accuracy: 0.6042 - val_loss: 0.0613 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0327 - accuracy: 0.6042 - val_loss: 0.0614 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0321 - accuracy: 0.6042 - val_loss: 0.0628 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0324 - accuracy: 0.6042 - val_loss: 0.0628 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0323 - accuracy: 0.6042 - val_loss: 0.0627 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0323 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0323 - accuracy: 0.6042 - val_loss: 0.0613 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0325 - accuracy: 0.6042 - val_loss: 0.0626 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0320 - accuracy: 0.6042 - val_loss: 0.0618 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0321 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0320 - accuracy: 0.6042 - val_loss: 0.0619 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0321 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0326 - accuracy: 0.6042 - val_loss: 0.0614 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0320 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0324 - accuracy: 0.6042 - val_loss: 0.0620 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0324 - accuracy: 0.6042 - val_loss: 0.0647 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0320 - accuracy: 0.6042 - val_loss: 0.0617 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0316 - accuracy: 0.6042 - val_loss: 0.0612 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0323 - accuracy: 0.6042 - val_loss: 0.0621 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0317 - accuracy: 0.6042 - val_loss: 0.0625 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0316 - accuracy: 0.6042 - val_loss: 0.0624 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0315 - accuracy: 0.6042 - val_loss: 0.0623 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0324 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0321 - accuracy: 0.6042 - val_loss: 0.0644 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0321 - accuracy: 0.6042 - val_loss: 0.0624 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0315 - accuracy: 0.6042 - val_loss: 0.0619 - val_accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0330 - accuracy: 0.6042 - val_loss: 0.0633 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0316 - accuracy: 0.6042 - val_loss: 0.0613 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0327 - accuracy: 0.6042 - val_loss: 0.0618 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0327 - accuracy: 0.6042 - val_loss: 0.0680 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0329 - accuracy: 0.6042 - val_loss: 0.0617 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0333 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0326 - accuracy: 0.6042 - val_loss: 0.0647 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0334 - accuracy: 0.6042 - val_loss: 0.0650 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0348 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0350 - accuracy: 0.6042 - val_loss: 0.0640 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0342 - accuracy: 0.6042 - val_loss: 0.0644 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0402 - accuracy: 0.6042 - val_loss: 0.0652 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0348 - accuracy: 0.6042 - val_loss: 0.0621 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0326 - accuracy: 0.6042 - val_loss: 0.0665 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0335 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0319 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0322 - accuracy: 0.6042 - val_loss: 0.0614 - val_accuracy: 0.7500\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0312 - accuracy: 0.6042 - val_loss: 0.0617 - val_accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0309 - accuracy: 0.6042 - val_loss: 0.0625 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0310 - accuracy: 0.6042 - val_loss: 0.0616 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0310 - accuracy: 0.6042 - val_loss: 0.0612 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0313 - accuracy: 0.6042 - val_loss: 0.0626 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0311 - accuracy: 0.6042 - val_loss: 0.0615 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0326 - accuracy: 0.8000\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 80.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data.data,columns = data.feature_names)\n",
    "df[\"species\"] = data.target\n",
    "df\n",
    "\n",
    "df.isnull().sum() # checking if null values present or not\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df.corr()\n",
    "\n",
    "x = df.iloc[:,:4]\n",
    "x\n",
    "\n",
    "y = df.iloc[:,4:]\n",
    "y\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(36,input_dim=4,activation='relu'))\n",
    "model.add(Dense(18,activation='relu'))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=200,validation_split=0.2)\n",
    "\n",
    "_,accuracy = model.evaluate(x_test,y_test)\n",
    "print('\\n\\n')\n",
    "print('Accuracy: %.2f'%(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc4380",
   "metadata": {},
   "source": [
    "# Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7672904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  0  0]\n",
      " [ 0 39  0]\n",
      " [ 0 11 31]]\n",
      "\n",
      "Correct Predictions:  109\n",
      "\n",
      "False Predictions:  11\n",
      "\n",
      "Accuracy: 90.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['species'] = data.target\n",
    "df\n",
    "\n",
    "x = df.iloc[:,:4]\n",
    "x\n",
    "\n",
    "y = df.iloc[:,4:]\n",
    "y\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.20,random_state=82)\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "\n",
    "nvclassifier = GaussianNB()\n",
    "nvclassifier.fit(x_train,y_train)\n",
    "\n",
    "y_pred = nvclassifier.predict(x_test)\n",
    "y_pred\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "\n",
    "a = cm.shape\n",
    "corrpred = 0\n",
    "falsepred = 0\n",
    "\n",
    "for row in range(a[0]):\n",
    "    for c in range(a[1]):\n",
    "        if row == c:\n",
    "            corrpred += cm[row,c]\n",
    "        else:\n",
    "            falsepred += cm[row,c]\n",
    "            \n",
    "print('\\nCorrect Predictions: ',corrpred)\n",
    "print('\\nFalse Predictions: ',falsepred)\n",
    "print('\\nAccuracy: %.2f' %(corrpred/(cm.sum())*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a783db",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6aa7524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n",
      "\n",
      "[5. 6.]\n",
      "\n",
      "[[-4. -4.]\n",
      " [-2. -2.]\n",
      " [ 0.  0.]\n",
      " [ 2.  2.]\n",
      " [ 4.  4.]]\n",
      "\n",
      "[[10. 10.]\n",
      " [10. 10.]]\n",
      "\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "[2.00000000e+01 2.22044605e-15]\n",
      "\n",
      "[[-5.65685425e+00 -4.44089210e-16]\n",
      " [-2.82842712e+00 -2.22044605e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 2.82842712e+00  2.22044605e-16]\n",
      " [ 5.65685425e+00  4.44089210e-16]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "\n",
    "\n",
    "A = array([[1,2],[3,4],[5,6],[7,8],[9,10]])\n",
    "print(A)\n",
    "\n",
    "M = mean(A.T,axis=1)\n",
    "print()\n",
    "print(M)\n",
    "\n",
    "C = A - M\n",
    "print()\n",
    "print(C)\n",
    "\n",
    "V = cov(C.T)\n",
    "print()\n",
    "print(V)\n",
    "\n",
    "values,vectors = eig(V)\n",
    "print()\n",
    "print(vectors)\n",
    "print(values)\n",
    "\n",
    "\n",
    "P = vectors.T.dot(C.T)\n",
    "print()\n",
    "print(P.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26306399",
   "metadata": {},
   "source": [
    "# Gray Level Co-occurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "07191450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.16666667 0.11111111 0.25       0.22222222]]\n",
      "\n",
      "  [[0.08333333 0.05555556 0.         0.05555556]]\n",
      "\n",
      "  [[0.04166667 0.16666667 0.08333333 0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.08333333 0.05555556 0.         0.05555556]]\n",
      "\n",
      "  [[0.16666667 0.11111111 0.16666667 0.11111111]]\n",
      "\n",
      "  [[0.         0.05555556 0.08333333 0.11111111]]\n",
      "\n",
      "  [[0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.04166667 0.16666667 0.08333333 0.        ]]\n",
      "\n",
      "  [[0.         0.05555556 0.08333333 0.11111111]]\n",
      "\n",
      "  [[0.25       0.         0.08333333 0.22222222]]\n",
      "\n",
      "  [[0.04166667 0.11111111 0.08333333 0.05555556]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.04166667 0.11111111 0.08333333 0.05555556]]\n",
      "\n",
      "  [[0.08333333 0.         0.         0.        ]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import greycomatrix\n",
    "import numpy as np\n",
    "\n",
    "image = np.array([[0,0,1,1],[0,0,1,1],[0,2,2,2],[2,2,3,3]])\n",
    "image\n",
    "\n",
    "result = greycomatrix(image,[1],[0,np.pi/4,np.pi/2,3*np.pi/4],levels=4,symmetric=True,normed=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80099d",
   "metadata": {},
   "source": [
    "# Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d06eb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1]\n",
      "\n",
      "[1]\n",
      "\n",
      "[0]\n",
      "\n",
      "[[ 1.  2.]\n",
      " [10.  2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,2],[1,4],[1,0],[10,2],[10,4],[10,0]])\n",
    "x\n",
    "\n",
    "kmeans = KMeans(n_clusters=2,random_state=1).fit(x)\n",
    "print(kmeans.labels_)\n",
    "print()\n",
    "print(kmeans.predict([[12,3]]))\n",
    "print()\n",
    "print(kmeans.predict([[2,4]]))\n",
    "print()\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb8c14",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "971feb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  96.66666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['species'] = data.target\n",
    "df\n",
    "\n",
    "x = df.iloc[:,:4]\n",
    "x\n",
    "\n",
    "y = df.iloc[:,4:]\n",
    "y\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20)\n",
    "\n",
    "model = SVC(kernel='linear',C=1)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "svm_pred = model.predict(x_test)\n",
    "\n",
    "accuracy = model.score(x_test,y_test)\n",
    "\n",
    "print('Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8904c",
   "metadata": {},
   "source": [
    "# Building a Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3c200c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "22/22 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3333\n",
      "Epoch 2/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3333\n",
      "Epoch 3/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3400\n",
      "Epoch 4/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.4133\n",
      "Epoch 5/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5933\n",
      "Epoch 6/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 7/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 8/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 9/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 10/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 11/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 12/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 13/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 14/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 15/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 16/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 17/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 18/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 19/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 20/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 21/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 22/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 23/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 24/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 25/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 26/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 27/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 28/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 29/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 30/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 31/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 32/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 33/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 34/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 35/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 36/700\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 37/700\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 38/700\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 39/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 40/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 41/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 42/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 43/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 44/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 45/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 46/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 47/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 48/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 49/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 50/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 51/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 52/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 53/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 54/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 55/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 56/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 57/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 58/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 59/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 60/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 61/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 62/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 63/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 64/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 65/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 66/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 67/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 68/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 69/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 70/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 71/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 72/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 73/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 74/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 75/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 76/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 77/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 78/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 79/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 80/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 81/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 82/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 83/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 84/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 85/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 86/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 87/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 88/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 89/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 90/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 91/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 92/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 93/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 94/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 95/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 96/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 97/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 98/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 99/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 100/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 101/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 102/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 103/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 104/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 105/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 106/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 107/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 108/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 109/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 110/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 111/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 112/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 113/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 114/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 115/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 116/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 117/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 118/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 119/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 120/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 121/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 122/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 123/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 124/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 125/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 126/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 127/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 128/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 129/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 130/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 131/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 132/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 133/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 134/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 135/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 136/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 137/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 138/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 139/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 140/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 141/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 142/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 143/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 144/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 145/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 146/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 147/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 148/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 149/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 150/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 151/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 152/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 153/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 154/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 155/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 156/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 157/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 158/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 159/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 160/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 161/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 162/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 163/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 164/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 165/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 166/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 167/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 168/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 169/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 170/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 171/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 172/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 173/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 174/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 175/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 176/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 177/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 178/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 179/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 180/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 181/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 182/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 183/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 184/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 185/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 186/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 187/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 188/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 189/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 190/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 191/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 192/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 193/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 194/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 195/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 196/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 197/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 198/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 199/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 200/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 201/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 202/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 203/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 204/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 205/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 206/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 207/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 208/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 209/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 210/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 211/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 212/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 213/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 214/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 215/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 216/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 217/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 218/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 219/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 220/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 221/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 222/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 223/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 224/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 225/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 226/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 227/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 228/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 229/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 230/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 231/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 232/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 233/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 234/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 235/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 236/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 237/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 238/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 239/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 240/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 241/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 242/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 243/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 244/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 245/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 246/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 247/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 248/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 249/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 250/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 251/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 252/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 253/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 254/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 255/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 256/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 257/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 258/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 259/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 260/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 261/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 262/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 263/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 264/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 265/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 266/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 267/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 268/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 269/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 270/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 271/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 272/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 273/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 274/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 275/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 276/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 277/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 278/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 279/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 280/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 281/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 282/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 283/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 284/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 285/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 286/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 287/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 288/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 289/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 290/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 291/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 292/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 293/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 294/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 295/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 296/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 297/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 298/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 299/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 300/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 301/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 302/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 303/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 304/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 305/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 306/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 307/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 308/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 309/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 310/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 311/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 312/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 313/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 314/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 315/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 316/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 317/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 318/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 319/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 320/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 321/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 322/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 323/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 324/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 325/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 326/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 327/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 328/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 329/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 330/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 331/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 332/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 333/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 334/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 335/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 336/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 337/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 338/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 339/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 340/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 341/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 342/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 343/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 344/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 345/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 346/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 347/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 348/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 349/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 350/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 351/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 352/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 353/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 354/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 355/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 356/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 357/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 358/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 359/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 360/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 361/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 362/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 363/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 364/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 365/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 366/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 367/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 368/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 369/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 370/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 371/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 372/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 373/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 374/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 375/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 376/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 377/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 378/700\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 379/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 380/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 381/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 382/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 383/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 384/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 385/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 386/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 387/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 388/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 389/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 390/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 391/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 392/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 393/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 394/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 395/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 396/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 397/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 398/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 399/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 400/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 401/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 402/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 403/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 404/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 405/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 406/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 407/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 408/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 409/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 410/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 411/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 412/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 413/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 414/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 415/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 416/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 417/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 418/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 419/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 420/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 421/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 422/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 423/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 424/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 425/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 426/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 427/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 428/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 429/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 430/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 431/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 432/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 433/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 434/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 435/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 436/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 437/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 438/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 439/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 440/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 441/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 442/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 443/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 444/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 445/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 446/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 447/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 448/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 449/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 450/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 451/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 452/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 453/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 454/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 455/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 456/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 457/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 458/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 459/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 460/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 461/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 462/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 463/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 464/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 465/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 466/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 467/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 468/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 469/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 470/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 471/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 472/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 473/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 474/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 475/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 476/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 477/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 478/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 479/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 480/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 481/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 482/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 483/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 484/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 485/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 486/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 487/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 488/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 489/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 490/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 491/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 492/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 493/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 494/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 495/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 496/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 497/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 498/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 499/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 500/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 501/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 502/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 503/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 504/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 505/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 506/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 507/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 508/700\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 509/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 510/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 511/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 512/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 513/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 514/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 515/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 516/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 517/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 518/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 519/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 520/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 521/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 522/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 523/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 524/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 525/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 526/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 527/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 528/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 529/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 530/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 531/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 532/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 533/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 534/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 535/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 536/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 537/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 538/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 539/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 540/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 541/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 542/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 543/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 544/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 545/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 546/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 547/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 548/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 549/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 550/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 551/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 552/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 553/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 554/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 555/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 556/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 557/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 558/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 559/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 560/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 561/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 562/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 563/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 564/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 565/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 566/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 567/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 568/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 569/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 570/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 571/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 572/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 573/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 574/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 575/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 576/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 577/700\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 578/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 579/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 580/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 581/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 582/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 583/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 584/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 585/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 586/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 587/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 588/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 589/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 590/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 591/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 592/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 593/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 594/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 595/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 596/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 597/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 598/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 599/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 600/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 601/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 602/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 603/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 604/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 605/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 606/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 607/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 608/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 609/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 610/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 611/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 612/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 613/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 614/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 615/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 616/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 617/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 618/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 619/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 620/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 621/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 622/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 623/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 624/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 626/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 627/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 628/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 629/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 630/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 631/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 632/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 633/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 634/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 635/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 636/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 637/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 638/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 639/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 640/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 641/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 642/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 643/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 644/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 645/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 646/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 647/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 648/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 649/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 650/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 651/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 652/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 653/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 654/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 655/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 656/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 657/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 658/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 659/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 660/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 661/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 662/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 663/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 664/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 665/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 666/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 667/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 668/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 669/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 670/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 671/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 672/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 673/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 674/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 675/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 676/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 677/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 678/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 679/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 680/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 681/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 682/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 683/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 684/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 685/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 686/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 687/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 688/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 689/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 690/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 691/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 692/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 693/700\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 694/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 695/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 696/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 697/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 698/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 699/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 700/700\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Accuracy:  66.66666865348816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "data\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['species'] = data.target\n",
    "df\n",
    "\n",
    "x = df.iloc[:,:4]\n",
    "x\n",
    "\n",
    "y = df.iloc[:,4:]\n",
    "y\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(36,input_dim=4,activation='relu'))\n",
    "model.add(Dense(18,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x,y,epochs=700,batch_size=7)\n",
    "\n",
    "_,accuracy = model.evaluate(x,y)\n",
    "\n",
    "print('Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba3275",
   "metadata": {},
   "source": [
    "# Importance Of Data Preprocessing in Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c756c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.4667\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
      "\n",
      "Accuracy:  66.66666865348816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "data\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['species'] = data.target\n",
    "df\n",
    "\n",
    "x = df.iloc[:,:4]\n",
    "x\n",
    "\n",
    "y = df.iloc[:,4:]\n",
    "y\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(36,input_dim=4,activation='relu'))\n",
    "model.add(Dense(18,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x,y,epochs=200,batch_size=10)\n",
    "\n",
    "_,accuracy = model.evaluate(x,y)\n",
    "\n",
    "print('\\nAccuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6d4168a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.901  1.019 -1.34  -1.315]\n",
      " [-1.143 -0.132 -1.34  -1.315]\n",
      " [-1.385  0.328 -1.397 -1.315]\n",
      " [-1.507  0.098 -1.283 -1.315]\n",
      " [-1.022  1.249 -1.34  -1.315]]\n",
      "\n",
      "[[0.804 0.552 0.221 0.032]\n",
      " [0.828 0.507 0.237 0.034]\n",
      " [0.805 0.548 0.223 0.034]\n",
      " [0.8   0.539 0.261 0.035]\n",
      " [0.791 0.569 0.221 0.032]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler().fit(x)\n",
    "rescaledx = scaler.transform(x)\n",
    "np.set_printoptions(precision=3)\n",
    "print(rescaledx[0:5,:])\n",
    "\n",
    "print()\n",
    "\n",
    "scaler = Normalizer().fit(x)\n",
    "normalizedx = scaler.transform(x)\n",
    "np.set_printoptions(precision=3)\n",
    "print(normalizedx[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "96a28805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2733\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.5933\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6200\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6333\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "\n",
      "Accuracy:  64.66666460037231\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36,input_dim=4,activation='relu'))\n",
    "model.add(Dense(18,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(rescaledx,y,epochs=200,batch_size=10)\n",
    "\n",
    "_,accuracy = model.evaluate(rescaledx,y)\n",
    "\n",
    "print('\\nAccuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b76f8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3733\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.4200\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5400\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.4600\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5733\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.5267\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5800\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6067\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6467\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6600\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6533\n",
      "\n",
      "Accuracy:  65.3333306312561\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36,input_dim=4,activation='relu'))\n",
    "model.add(Dense(18,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(normalizedx,y,epochs=200,batch_size=10)\n",
    "\n",
    "_,accuracy = model.evaluate(normalizedx,y)\n",
    "\n",
    "print('\\nAccuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844bf1c",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fcd58b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.1, 54), (6.2, 75), (5.8, 67), (5.5, 65), (5.0, 54), (5.3, 59), (6.0, 69)]\n",
      "     X   Y\n",
      "0  5.1  54\n",
      "1  6.2  75\n",
      "2  5.8  67\n",
      "3  5.5  65\n",
      "4  5.0  54\n",
      "5  5.3  59\n",
      "6  6.0  69\n",
      "11.054217552953162 1.9396429551719239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.26494827289089"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Inatializing m and c\n",
    "m = 0\n",
    "c = 0\n",
    "\n",
    "X = [5.1,6.2,5.8,5.5,5.0,5.3,6.0]  # Height\n",
    "Y = [54,75,67,65,54,59,69]         # Weight\n",
    "\n",
    "# create a list of X and Y pair\n",
    "print(list(zip(X,Y)))     \n",
    "\n",
    "# create dataframe for the table of values\n",
    "data = pd.DataFrame(list(zip(X,Y)),columns=['X','Y'])\n",
    "\n",
    "print(data)\n",
    "\n",
    "X = data['X']\n",
    "X\n",
    "\n",
    "Y = data['Y']\n",
    "Y\n",
    "\n",
    "# Learning Rate\n",
    "L = 0.0001\n",
    "\n",
    "# Number of iterations to perform gradient descent\n",
    "epoches = 1000\n",
    "\n",
    "# number of elements in X\n",
    "n = float(len(X))\n",
    "\n",
    "# Performing Gradient Descent\n",
    "for i in range(epoches):\n",
    "    Y_pred = m*X+c\n",
    "    D_m = (-2/n)*np.sum(X*(Y-Y_pred))\n",
    "    D_c = (-2/n)*np.sum(Y-Y_pred)\n",
    "    m = m-L*D_m\n",
    "    c = c-L*D_c\n",
    "    \n",
    "print(m,c)\n",
    "\n",
    "def predict(x):\n",
    "    return m*x+c\n",
    "\n",
    "predict(6.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
